{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f1797bb-ba7b-42f8-8250-ecc08b249e6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda_available?  True\n",
      "Name:  NVIDIA RTX A6000\n",
      "Device count:  1\n",
      "current device:  0\n",
      "Select device:  <torch.cuda.device object at 0x7fcf0edd3af0>\n",
      "get device name:  NVIDIA RTX A6000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Cuda_available? \", torch.cuda.is_available())\n",
    "print(\"Name: \", torch.cuda.get_device_name(0))\n",
    "print(\"Device count: \", torch.cuda.device_count())\n",
    "print(\"current device: \", torch.cuda.current_device())\n",
    "print(\"Select device: \", torch.cuda.device(0))\n",
    "print(\"get device name: \",torch.cuda.get_device_name(0))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #finally got the solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37b08094-5b7c-469c-b411-72a227b45b84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'nnUNet'...\n",
      "remote: Enumerating objects: 10831, done.\u001b[K\n",
      "remote: Counting objects: 100% (10831/10831), done.\u001b[K\n",
      "remote: Compressing objects: 100% (2686/2686), done.\u001b[K\n",
      "remote: Total 10831 (delta 8329), reused 10380 (delta 8122), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (10831/10831), 5.31 MiB | 7.58 MiB/s, done.\n",
      "Resolving deltas: 100% (8329/8329), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/MIC-DKFZ/nnUNet.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b40a4d3f-a1b8-49e4-b58d-5c7bc6d9ff1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/nnUNet\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting dynamic-network-architectures>=0.2\n",
      "  Using cached dynamic_network_architectures-0.2-py3-none-any.whl\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from nnunetv2==2.1.2) (1.2.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from nnunetv2==2.1.2) (1.24.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from nnunetv2==2.1.2) (1.10.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from nnunetv2==2.1.2) (2.29.0)\n",
      "Collecting batchgenerators>=0.25\n",
      "  Using cached batchgenerators-0.25-py3-none-any.whl\n",
      "Collecting graphviz\n",
      "  Using cached graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "Collecting SimpleITK>=2.2.1\n",
      "  Using cached SimpleITK-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.7 MB)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from nnunetv2==2.1.2) (2.0.1)\n",
      "Collecting dicom2nifti\n",
      "  Using cached dicom2nifti-2.4.8-py3-none-any.whl (43 kB)\n",
      "Requirement already satisfied: scikit-image>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from nnunetv2==2.1.2) (0.20.0)\n",
      "Collecting acvl-utils>=0.2\n",
      "  Using cached acvl_utils-0.2-py3-none-any.whl\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from nnunetv2==2.1.2) (2.0.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from nnunetv2==2.1.2) (3.7.1)\n",
      "Collecting imagecodecs\n",
      "  Using cached imagecodecs-2023.8.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.8 MB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nnunetv2==2.1.2) (4.65.0)\n",
      "Collecting nibabel\n",
      "  Using cached nibabel-5.1.0-py3-none-any.whl (3.3 MB)\n",
      "Collecting yacs\n",
      "  Using cached yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: tifffile in /opt/conda/lib/python3.10/site-packages (from nnunetv2==2.1.2) (2023.4.12)\n",
      "Collecting connected-components-3d\n",
      "  Using cached connected_components_3d-3.12.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Requirement already satisfied: threadpoolctl in /opt/conda/lib/python3.10/site-packages (from batchgenerators>=0.25->nnunetv2==2.1.2) (3.1.0)\n",
      "Collecting unittest2\n",
      "  Using cached unittest2-1.1.0-py2.py3-none-any.whl (96 kB)\n",
      "Collecting future\n",
      "  Using cached future-0.18.3-py3-none-any.whl\n",
      "Requirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from batchgenerators>=0.25->nnunetv2==2.1.2) (9.4.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.19.3->nnunetv2==2.1.2) (0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.19.3->nnunetv2==2.1.2) (23.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.19.3->nnunetv2==2.1.2) (1.4.1)\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.19.3->nnunetv2==2.1.2) (3.1)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.19.3->nnunetv2==2.1.2) (2.28.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->nnunetv2==2.1.2) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->nnunetv2==2.1.2) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->nnunetv2==2.1.2) (1.12)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->nnunetv2==2.1.2) (3.1.2)\n",
      "Collecting python-gdcm\n",
      "  Using cached python_gdcm-3.0.22-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "Collecting pydicom>=2.2.0\n",
      "  Using cached pydicom-2.4.2-py3-none-any.whl (1.8 MB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->nnunetv2==2.1.2) (1.0.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->nnunetv2==2.1.2) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->nnunetv2==2.1.2) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->nnunetv2==2.1.2) (4.39.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->nnunetv2==2.1.2) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->nnunetv2==2.1.2) (0.11.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->nnunetv2==2.1.2) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->nnunetv2==2.1.2) (2022.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->nnunetv2==2.1.2) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->nnunetv2==2.1.2) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->nnunetv2==2.1.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->nnunetv2==2.1.2) (3.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->nnunetv2==2.1.2) (1.2.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from yacs->nnunetv2==2.1.2) (6.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->nnunetv2==2.1.2) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->nnunetv2==2.1.2) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.0.0->nnunetv2==2.1.2) (1.3.0)\n",
      "Collecting traceback2\n",
      "  Using cached traceback2-1.4.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting argparse\n",
      "  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting linecache2\n",
      "  Using cached linecache2-1.0.0-py2.py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: nnunetv2\n",
      "  Building editable for nnunetv2 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nnunetv2: filename=nnunetv2-2.1.2-0.editable-py3-none-any.whl size=16242 sha256=51af48531facc6470f8fb2b6cc7f459f891929b44993d447aa5a881f82dbad27\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-l_6hhq81/wheels/6a/bd/32/3786ee52d0f4cfdb8351babb58ff37a72ef30985cbf8497d13\n",
      "Successfully built nnunetv2\n",
      "Installing collected packages: SimpleITK, linecache2, argparse, yacs, traceback2, python-gdcm, pydicom, nibabel, imagecodecs, graphviz, future, connected-components-3d, unittest2, dicom2nifti, seaborn, dynamic-network-architectures, batchgenerators, acvl-utils, nnunetv2\n",
      "Successfully installed SimpleITK-2.2.1 acvl-utils-0.2 argparse-1.4.0 batchgenerators-0.25 connected-components-3d-3.12.2 dicom2nifti-2.4.8 dynamic-network-architectures-0.2 future-0.18.3 graphviz-0.20.1 imagecodecs-2023.8.12 linecache2-1.0.0 nibabel-5.1.0 nnunetv2-2.1.2 pydicom-2.4.2 python-gdcm-3.0.22 seaborn-0.12.2 traceback2-1.4.0 unittest2-1.1.0 yacs-0.1.8\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install -e nnUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e42aabf1-a252-4d71-b77e-ac0ae58d6872",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['nnUNet_raw'] ='data'\n",
    "os.environ['nnUNet_preprocessed'] ='nnUNet_preprocessed'\n",
    "os.environ['nnUNet_results'] ='result_folder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8b750f4-5e3a-49b7-abf0-85ef39341a7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fingerprint extraction...\n",
      "Dataset013_PETCTDB\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
      "\n",
      "####################\n",
      "verify_dataset_integrity Done. \n",
      "If you didn't see any error messages then your dataset is most likely OK!\n",
      "####################\n",
      "\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
      "100%|█████████████████████████████████████████| 109/109 [02:25<00:00,  1.33s/it]\n",
      "Experiment planning...\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [3.09       2.09751271 2.09751271]. \n",
      "Current patch size: [128 128 128]. \n",
      "Current median shape: [316.50485437 388.34951456 388.34951456]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [3.1827     2.16043809 2.16043809]. \n",
      "Current patch size: [128 128 128]. \n",
      "Current median shape: [307.28626638 377.03836365 377.03836365]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [3.278181   2.22525123 2.22525123]. \n",
      "Current patch size: [128 128 128]. \n",
      "Current median shape: [298.33618095 366.05666374 366.05666374]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [3.37652643 2.29200877 2.29200877]. \n",
      "Current patch size: [128 128 128]. \n",
      "Current median shape: [289.64677762 355.39481917 355.39481917]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [3.47782222 2.36076903 2.36076903]. \n",
      "Current patch size: [128 128 128]. \n",
      "Current median shape: [281.21046371 345.04351375 345.04351375]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [3.58215689 2.43159211 2.43159211]. \n",
      "Current patch size: [128 128 128]. \n",
      "Current median shape: [273.01986768 334.99370267 334.99370267]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [3.6896216  2.50453987 2.50453987]. \n",
      "Current patch size: [128 128 128]. \n",
      "Current median shape: [265.0678327  325.23660454 325.23660454]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [3.80031024 2.57967606 2.57967606]. \n",
      "Current patch size: [128 128 128]. \n",
      "Current median shape: [257.34741039 315.76369373 315.76369373]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [3.91431955 2.65706635 2.65706635]. \n",
      "Current patch size: [128 128 128]. \n",
      "Current median shape: [249.85185474 306.56669294 306.56669294]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [4.03174914 2.73677834 2.73677834]. \n",
      "Current patch size: [128 128 128]. \n",
      "Current median shape: [242.57461626 297.63756596 297.63756596]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [4.15270161 2.81888169 2.81888169]. \n",
      "Current patch size: [128 128 128]. \n",
      "Current median shape: [235.50933617 288.96851064 288.96851064]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [4.27728266 2.90344814 2.90344814]. \n",
      "Current patch size: [128 128 128]. \n",
      "Current median shape: [228.64984094 280.55195208 280.55195208]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [4.40560114 2.99055158 2.99055158]. \n",
      "Current patch size: [128 128 128]. \n",
      "Current median shape: [221.99013684 272.380536   272.380536  ]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [4.53776917 3.08026813 3.08026813]. \n",
      "Current patch size: [128 128 128]. \n",
      "Current median shape: [215.5244047  264.44712233 264.44712233]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [4.67390225 3.17267617 3.17267617]. \n",
      "Current patch size: [128 128 128]. \n",
      "Current median shape: [209.24699485 256.74477896 256.74477896]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [4.81411932 3.26785646 3.26785646]. \n",
      "Current patch size: [128 128 128]. \n",
      "Current median shape: [203.15242219 249.26677569 249.26677569]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [4.9585429  3.36589215 3.36589215]. \n",
      "Current patch size: [128 128 128]. \n",
      "Current median shape: [197.23536135 242.00657834 242.00657834]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [5.10729918 3.46686892 3.46686892]. \n",
      "Current patch size: [128 128 128]. \n",
      "Current median shape: [191.49064208 234.95784305 234.95784305]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [5.26051816 3.57087498 3.57087498]. \n",
      "Current patch size: [128 128 128]. \n",
      "Current median shape: [185.91324474 228.11441072 228.11441072]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [5.4183337  3.67800123 3.67800123]. \n",
      "Current patch size: [128 128 128]. \n",
      "Current median shape: [180.49829586 221.47030167 221.47030167]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [5.58088372 3.78834127 3.78834127]. \n",
      "Current patch size: [128 128 128]. \n",
      "Current median shape: [175.24106395 215.01971036 215.01971036]\n",
      "2D U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 16, 'patch_size': array([448, 448]), 'median_image_size_in_voxels': array([400., 400.]), 'spacing': array([2.03642011, 2.03642011]), 'normalization_schemes': ['ZScoreNormalization', 'CTNormalization'], 'use_mask_for_norm': [False, False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': (2, 2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2, 2), 'num_pool_per_axis': [6, 6], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True}\n",
      "\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
      "3D lowres U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_3d_lowres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': array([128, 128, 128]), 'median_image_size_in_voxels': [175, 215, 215], 'spacing': array([5.58088372, 3.78834127, 3.78834127]), 'normalization_schemes': ['ZScoreNormalization', 'CTNormalization'], 'use_mask_for_norm': [False, False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'num_pool_per_axis': [5, 5, 5], 'pool_op_kernel_sizes': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'unet_max_num_features': 320, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': False, 'next_stage': '3d_cascade_fullres'}\n",
      "\n",
      "3D fullres U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': array([128, 128, 128]), 'median_image_size_in_voxels': array([326., 400., 400.]), 'spacing': array([3.        , 2.03642011, 2.03642011]), 'normalization_schemes': ['ZScoreNormalization', 'CTNormalization'], 'use_mask_for_norm': [False, False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'num_pool_per_axis': [5, 5, 5], 'pool_op_kernel_sizes': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'unet_max_num_features': 320, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True}\n",
      "\n",
      "Plans were saved to nnUNet_preprocessed/Dataset013_PETCTDB/nnUNetPlans.json\n",
      "Preprocessing...\n",
      "Preprocessing dataset Dataset013_PETCTDB\n",
      "Configuration: 2d...\n",
      "100%|█████████████████████████████████████████| 109/109 [05:41<00:00,  3.13s/it]\n",
      "Configuration: 3d_fullres...\n",
      "100%|█████████████████████████████████████████| 109/109 [08:00<00:00,  4.41s/it]\n",
      "Configuration: 3d_lowres...\n",
      "100%|█████████████████████████████████████████| 109/109 [13:36<00:00,  7.49s/it]\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_plan_and_preprocess -d 013 --verify_dataset_integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2989252-acb3-448e-ab0b-0b7f1ea44516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/FabianIsensee/hiddenlayer.git\n",
      "  Cloning https://github.com/FabianIsensee/hiddenlayer.git to /tmp/pip-req-build-fr0fyz29\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/FabianIsensee/hiddenlayer.git /tmp/pip-req-build-fr0fyz29\n",
      "  Resolved https://github.com/FabianIsensee/hiddenlayer.git to commit b7263b6dc4569da1b6dea5964e1eac78fa32fa77\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade git+https://github.com/FabianIsensee/hiddenlayer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8d22c3b-80f8-4e7b-8af2-ec3594ea80b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 3d_fullres\n",
      " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [326.0, 400.0, 400.0], 'spacing': [3.0, 2.0364201068878174, 2.0364201068878174], 'normalization_schemes': ['ZScoreNormalization', 'CTNormalization'], 'use_mask_for_norm': [False, False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'num_pool_per_axis': [5, 5, 5], 'pool_op_kernel_sizes': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'unet_max_num_features': 320, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset013_PETCTDB', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [3.0, 2.0364201068878174, 2.0364201068878174], 'original_median_shape_after_transp': [326, 400, 400], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 167.9757537841797, 'mean': 5.435083991534125, 'median': 3.9277126789093018, 'min': 0.09483639150857925, 'percentile_00_5': 1.1182502508163452, 'percentile_99_5': 26.928308486938477, 'std': 4.513973614205279}, '1': {'max': 3412.23974609375, 'mean': 0.09971613855090386, 'median': 49.86198425292969, 'min': -1464.62890625, 'percentile_00_5': -830.406982421875, 'percentile_99_5': 714.96435546875, 'std': 228.73367229561458}}} \n",
      "\n",
      "2023-08-15 19:59:11.220729: unpacking dataset...\n",
      "2023-08-15 19:59:15.710507: unpacking done...\n",
      "2023-08-15 19:59:15.712086: do_dummy_2d_data_aug: False\n",
      "2023-08-15 19:59:15.714004: Using splits from existing split file: nnUNet_preprocessed/Dataset013_PETCTDB/splits_final.json\n",
      "2023-08-15 19:59:15.714471: The split file contains 5 splits.\n",
      "2023-08-15 19:59:15.714572: Desired fold for training: 0\n",
      "2023-08-15 19:59:15.714660: This split has 87 training and 22 validation cases.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/onnx/symbolic_helper.py:1466: UserWarning: ONNX export mode is set to TrainingMode.EVAL, but operator 'instance_norm' is set to train=True. Exporting with train=True.\n",
      "  warnings.warn(\n",
      "2023-08-15 19:59:20.254481: Unable to plot network architecture:\n",
      "2023-08-15 19:59:20.254569: failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH\n",
      "2023-08-15 19:59:20.294524: \n",
      "2023-08-15 19:59:20.294596: Epoch 0\n",
      "2023-08-15 19:59:20.294765: Current learning rate: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2023-08-15 20:02:14.682251: train_loss -0.0877\n",
      "2023-08-15 20:02:14.682514: val_loss -0.2025\n",
      "2023-08-15 20:02:14.682636: Pseudo dice [0.2868]\n",
      "2023-08-15 20:02:14.692126: Epoch time: 174.39 s\n",
      "2023-08-15 20:02:14.692294: Yayy! New best EMA pseudo Dice: 0.2868\n",
      "2023-08-15 20:02:18.174787: \n",
      "2023-08-15 20:02:18.175227: Epoch 1\n",
      "2023-08-15 20:02:18.175724: Current learning rate: 0.00999\n",
      "2023-08-15 20:04:45.633843: train_loss -0.2269\n",
      "2023-08-15 20:04:45.634243: val_loss -0.1798\n",
      "2023-08-15 20:04:45.634349: Pseudo dice [0.2667]\n",
      "2023-08-15 20:04:45.634510: Epoch time: 147.46 s\n",
      "2023-08-15 20:04:49.089443: \n",
      "2023-08-15 20:04:49.089947: Epoch 2\n",
      "2023-08-15 20:04:49.090132: Current learning rate: 0.00998\n",
      "2023-08-15 20:07:30.184050: train_loss -0.2411\n",
      "2023-08-15 20:07:30.184341: val_loss -0.1986\n",
      "2023-08-15 20:07:30.184426: Pseudo dice [0.2058]\n",
      "2023-08-15 20:07:30.184534: Epoch time: 161.1 s\n",
      "2023-08-15 20:07:34.605268: \n",
      "2023-08-15 20:07:34.605432: Epoch 3\n",
      "2023-08-15 20:07:34.605599: Current learning rate: 0.00997\n",
      "2023-08-15 20:10:10.709089: train_loss -0.2623\n",
      "2023-08-15 20:10:10.709438: val_loss -0.1915\n",
      "2023-08-15 20:10:10.709584: Pseudo dice [0.3032]\n",
      "2023-08-15 20:10:10.709676: Epoch time: 156.11 s\n",
      "2023-08-15 20:10:14.826288: \n",
      "2023-08-15 20:10:14.826584: Epoch 4\n",
      "2023-08-15 20:10:14.826702: Current learning rate: 0.00996\n",
      "2023-08-15 20:12:48.944767: train_loss -0.2611\n",
      "2023-08-15 20:12:48.952136: val_loss -0.2847\n",
      "2023-08-15 20:12:48.952291: Pseudo dice [0.3062]\n",
      "2023-08-15 20:12:48.952390: Epoch time: 154.12 s\n",
      "2023-08-15 20:12:50.827727: \n",
      "2023-08-15 20:12:50.827862: Epoch 5\n",
      "2023-08-15 20:12:50.827991: Current learning rate: 0.00995\n",
      "2023-08-15 20:15:15.787609: train_loss -0.3476\n",
      "2023-08-15 20:15:15.789241: val_loss -0.3284\n",
      "2023-08-15 20:15:15.789357: Pseudo dice [0.4655]\n",
      "2023-08-15 20:15:15.789447: Epoch time: 144.96 s\n",
      "2023-08-15 20:15:15.789512: Yayy! New best EMA pseudo Dice: 0.3005\n",
      "2023-08-15 20:15:19.744114: \n",
      "2023-08-15 20:15:19.744267: Epoch 6\n",
      "2023-08-15 20:15:19.744382: Current learning rate: 0.00995\n",
      "2023-08-15 20:17:37.748697: train_loss -0.3068\n",
      "2023-08-15 20:17:37.753418: val_loss -0.2401\n",
      "2023-08-15 20:17:37.753564: Pseudo dice [0.3853]\n",
      "2023-08-15 20:17:37.753655: Epoch time: 138.01 s\n",
      "2023-08-15 20:17:37.753720: Yayy! New best EMA pseudo Dice: 0.309\n",
      "2023-08-15 20:17:43.003815: \n",
      "2023-08-15 20:17:43.004176: Epoch 7\n",
      "2023-08-15 20:17:43.004355: Current learning rate: 0.00994\n",
      "2023-08-15 20:20:10.320919: train_loss -0.3799\n",
      "2023-08-15 20:20:10.323377: val_loss -0.3142\n",
      "2023-08-15 20:20:10.323494: Pseudo dice [0.5112]\n",
      "2023-08-15 20:20:10.323586: Epoch time: 147.32 s\n",
      "2023-08-15 20:20:10.323654: Yayy! New best EMA pseudo Dice: 0.3292\n",
      "2023-08-15 20:20:14.453659: \n",
      "2023-08-15 20:20:14.453830: Epoch 8\n",
      "2023-08-15 20:20:14.453954: Current learning rate: 0.00993\n",
      "2023-08-15 20:22:54.633765: train_loss -0.3501\n",
      "2023-08-15 20:22:54.635384: val_loss -0.3507\n",
      "2023-08-15 20:22:54.635486: Pseudo dice [0.4476]\n",
      "2023-08-15 20:22:54.635593: Epoch time: 160.18 s\n",
      "2023-08-15 20:22:54.635697: Yayy! New best EMA pseudo Dice: 0.3411\n",
      "2023-08-15 20:22:58.568217: \n",
      "2023-08-15 20:22:58.568390: Epoch 9\n",
      "2023-08-15 20:22:58.568521: Current learning rate: 0.00992\n",
      "2023-08-15 20:25:30.192172: train_loss -0.3455\n",
      "2023-08-15 20:25:30.195184: val_loss -0.3809\n",
      "2023-08-15 20:25:30.195339: Pseudo dice [0.5419]\n",
      "2023-08-15 20:25:30.195476: Epoch time: 151.63 s\n",
      "2023-08-15 20:25:30.195580: Yayy! New best EMA pseudo Dice: 0.3611\n",
      "2023-08-15 20:25:34.661608: \n",
      "2023-08-15 20:25:34.661888: Epoch 10\n",
      "2023-08-15 20:25:34.662009: Current learning rate: 0.00991\n",
      "2023-08-15 20:28:13.276625: train_loss -0.336\n",
      "2023-08-15 20:28:13.284895: val_loss -0.3977\n",
      "2023-08-15 20:28:13.285041: Pseudo dice [0.5861]\n",
      "2023-08-15 20:28:13.285139: Epoch time: 158.62 s\n",
      "2023-08-15 20:28:13.285208: Yayy! New best EMA pseudo Dice: 0.3836\n",
      "2023-08-15 20:28:16.719131: \n",
      "2023-08-15 20:28:16.719369: Epoch 11\n",
      "2023-08-15 20:28:16.719494: Current learning rate: 0.0099\n",
      "2023-08-15 20:30:40.080984: train_loss -0.3798\n",
      "2023-08-15 20:30:40.081869: val_loss -0.3637\n",
      "2023-08-15 20:30:40.081970: Pseudo dice [0.5095]\n",
      "2023-08-15 20:30:40.082057: Epoch time: 143.36 s\n",
      "2023-08-15 20:30:40.082124: Yayy! New best EMA pseudo Dice: 0.3962\n",
      "2023-08-15 20:30:43.570172: \n",
      "2023-08-15 20:30:43.570342: Epoch 12\n",
      "2023-08-15 20:30:43.570479: Current learning rate: 0.00989\n",
      "2023-08-15 20:33:07.365316: train_loss -0.3897\n",
      "2023-08-15 20:33:07.368082: val_loss -0.4219\n",
      "2023-08-15 20:33:07.368433: Pseudo dice [0.6356]\n",
      "2023-08-15 20:33:07.368624: Epoch time: 143.8 s\n",
      "2023-08-15 20:33:07.369251: Yayy! New best EMA pseudo Dice: 0.4202\n",
      "2023-08-15 20:33:11.067470: \n",
      "2023-08-15 20:33:11.067727: Epoch 13\n",
      "2023-08-15 20:33:11.067849: Current learning rate: 0.00988\n",
      "2023-08-15 20:35:23.223846: train_loss -0.3813\n",
      "2023-08-15 20:35:23.236227: val_loss -0.4206\n",
      "2023-08-15 20:35:23.236398: Pseudo dice [0.5682]\n",
      "2023-08-15 20:35:23.236622: Epoch time: 132.16 s\n",
      "2023-08-15 20:35:23.236699: Yayy! New best EMA pseudo Dice: 0.435\n",
      "2023-08-15 20:35:27.687742: \n",
      "2023-08-15 20:35:27.687887: Epoch 14\n",
      "2023-08-15 20:35:27.688026: Current learning rate: 0.00987\n",
      "2023-08-15 20:37:44.266287: train_loss -0.3751\n",
      "2023-08-15 20:37:44.268284: val_loss -0.3197\n",
      "2023-08-15 20:37:44.268394: Pseudo dice [0.4918]\n",
      "2023-08-15 20:37:44.268472: Epoch time: 136.58 s\n",
      "2023-08-15 20:37:44.268541: Yayy! New best EMA pseudo Dice: 0.4406\n",
      "2023-08-15 20:37:48.203364: \n",
      "2023-08-15 20:37:48.203538: Epoch 15\n",
      "2023-08-15 20:37:48.203677: Current learning rate: 0.00986\n",
      "2023-08-15 20:40:14.046978: train_loss -0.4182\n",
      "2023-08-15 20:40:14.068054: val_loss -0.38\n",
      "2023-08-15 20:40:14.068209: Pseudo dice [0.5868]\n",
      "2023-08-15 20:40:14.068297: Epoch time: 145.84 s\n",
      "2023-08-15 20:40:14.068360: Yayy! New best EMA pseudo Dice: 0.4553\n",
      "2023-08-15 20:40:17.659904: \n",
      "2023-08-15 20:40:17.660184: Epoch 16\n",
      "2023-08-15 20:40:17.660346: Current learning rate: 0.00986\n",
      "2023-08-15 20:42:34.566287: train_loss -0.4208\n",
      "2023-08-15 20:42:34.567815: val_loss -0.3958\n",
      "2023-08-15 20:42:34.568000: Pseudo dice [0.5623]\n",
      "2023-08-15 20:42:34.568099: Epoch time: 136.91 s\n",
      "2023-08-15 20:42:34.568170: Yayy! New best EMA pseudo Dice: 0.466\n",
      "2023-08-15 20:42:38.563457: \n",
      "2023-08-15 20:42:38.563587: Epoch 17\n",
      "2023-08-15 20:42:38.563696: Current learning rate: 0.00985\n",
      "2023-08-15 20:44:48.660406: train_loss -0.4088\n",
      "2023-08-15 20:44:48.676899: val_loss -0.4777\n",
      "2023-08-15 20:44:48.677026: Pseudo dice [0.5395]\n",
      "2023-08-15 20:44:48.677119: Epoch time: 130.1 s\n",
      "2023-08-15 20:44:48.677202: Yayy! New best EMA pseudo Dice: 0.4733\n",
      "2023-08-15 20:44:52.162175: \n",
      "2023-08-15 20:44:52.162349: Epoch 18\n",
      "2023-08-15 20:44:52.162470: Current learning rate: 0.00984\n",
      "2023-08-15 20:47:06.462073: train_loss -0.319\n",
      "2023-08-15 20:47:06.463857: val_loss -0.4299\n",
      "2023-08-15 20:47:06.464230: Pseudo dice [0.5947]\n",
      "2023-08-15 20:47:06.464510: Epoch time: 134.3 s\n",
      "2023-08-15 20:47:06.464673: Yayy! New best EMA pseudo Dice: 0.4855\n",
      "2023-08-15 20:47:10.157169: \n",
      "2023-08-15 20:47:10.157324: Epoch 19\n",
      "2023-08-15 20:47:10.157456: Current learning rate: 0.00983\n",
      "2023-08-15 20:49:27.976830: train_loss -0.3712\n",
      "2023-08-15 20:49:28.000042: val_loss -0.4681\n",
      "2023-08-15 20:49:28.000196: Pseudo dice [0.6372]\n",
      "2023-08-15 20:49:28.000284: Epoch time: 137.82 s\n",
      "2023-08-15 20:49:28.000354: Yayy! New best EMA pseudo Dice: 0.5006\n",
      "2023-08-15 20:49:31.902838: \n",
      "2023-08-15 20:49:31.903017: Epoch 20\n",
      "2023-08-15 20:49:31.903151: Current learning rate: 0.00982\n",
      "2023-08-15 20:51:39.726330: train_loss -0.3801\n",
      "2023-08-15 20:51:39.729112: val_loss -0.377\n",
      "2023-08-15 20:51:39.729267: Pseudo dice [0.6303]\n",
      "2023-08-15 20:51:39.729352: Epoch time: 127.82 s\n",
      "2023-08-15 20:51:39.729417: Yayy! New best EMA pseudo Dice: 0.5136\n",
      "2023-08-15 20:51:43.372239: \n",
      "2023-08-15 20:51:43.372370: Epoch 21\n",
      "2023-08-15 20:51:43.372483: Current learning rate: 0.00981\n",
      "2023-08-15 20:54:02.339180: train_loss -0.4276\n",
      "2023-08-15 20:54:02.340199: val_loss -0.5023\n",
      "2023-08-15 20:54:02.340316: Pseudo dice [0.6533]\n",
      "2023-08-15 20:54:02.340406: Epoch time: 138.97 s\n",
      "2023-08-15 20:54:02.340475: Yayy! New best EMA pseudo Dice: 0.5276\n",
      "2023-08-15 20:54:05.393756: \n",
      "2023-08-15 20:54:05.394089: Epoch 22\n",
      "2023-08-15 20:54:05.394232: Current learning rate: 0.0098\n",
      "2023-08-15 20:56:26.032610: train_loss -0.4097\n",
      "2023-08-15 20:56:26.034320: val_loss -0.4774\n",
      "2023-08-15 20:56:26.034421: Pseudo dice [0.6456]\n",
      "2023-08-15 20:56:26.034510: Epoch time: 140.64 s\n",
      "2023-08-15 20:56:26.034576: Yayy! New best EMA pseudo Dice: 0.5394\n",
      "2023-08-15 20:56:29.196489: \n",
      "2023-08-15 20:56:29.196678: Epoch 23\n",
      "2023-08-15 20:56:29.196836: Current learning rate: 0.00979\n",
      "2023-08-15 20:58:50.662318: train_loss -0.3737\n",
      "2023-08-15 20:58:50.662996: val_loss -0.4795\n",
      "2023-08-15 20:58:50.663094: Pseudo dice [0.621]\n",
      "2023-08-15 20:58:50.663179: Epoch time: 141.47 s\n",
      "2023-08-15 20:58:50.663254: Yayy! New best EMA pseudo Dice: 0.5475\n",
      "2023-08-15 20:58:53.894310: \n",
      "2023-08-15 20:58:53.894447: Epoch 24\n",
      "2023-08-15 20:58:53.894549: Current learning rate: 0.00978\n",
      "2023-08-15 21:01:13.455821: train_loss -0.4186\n",
      "2023-08-15 21:01:13.456390: val_loss -0.4459\n",
      "2023-08-15 21:01:13.456495: Pseudo dice [0.6046]\n",
      "2023-08-15 21:01:13.456577: Epoch time: 139.56 s\n",
      "2023-08-15 21:01:13.456644: Yayy! New best EMA pseudo Dice: 0.5532\n",
      "2023-08-15 21:01:16.463745: \n",
      "2023-08-15 21:01:16.463878: Epoch 25\n",
      "2023-08-15 21:01:16.464022: Current learning rate: 0.00977\n",
      "2023-08-15 21:03:35.441694: train_loss -0.4466\n",
      "2023-08-15 21:03:35.456049: val_loss -0.4308\n",
      "2023-08-15 21:03:35.456211: Pseudo dice [0.5388]\n",
      "2023-08-15 21:03:35.456308: Epoch time: 138.98 s\n",
      "2023-08-15 21:03:37.740190: \n",
      "2023-08-15 21:03:37.740334: Epoch 26\n",
      "2023-08-15 21:03:37.740436: Current learning rate: 0.00977\n",
      "2023-08-15 21:05:54.366468: train_loss -0.3995\n",
      "2023-08-15 21:05:54.368073: val_loss -0.4968\n",
      "2023-08-15 21:05:54.368293: Pseudo dice [0.6101]\n",
      "2023-08-15 21:05:54.368441: Epoch time: 136.63 s\n",
      "2023-08-15 21:05:54.368537: Yayy! New best EMA pseudo Dice: 0.5576\n",
      "2023-08-15 21:05:58.399011: \n",
      "2023-08-15 21:05:58.399312: Epoch 27\n",
      "2023-08-15 21:05:58.399458: Current learning rate: 0.00976\n",
      "2023-08-15 21:08:24.081041: train_loss -0.4122\n",
      "2023-08-15 21:08:24.082127: val_loss -0.4922\n",
      "2023-08-15 21:08:24.082227: Pseudo dice [0.6576]\n",
      "2023-08-15 21:08:24.082310: Epoch time: 145.68 s\n",
      "2023-08-15 21:08:24.082373: Yayy! New best EMA pseudo Dice: 0.5676\n",
      "2023-08-15 21:08:28.663963: \n",
      "2023-08-15 21:08:28.664376: Epoch 28\n",
      "2023-08-15 21:08:28.664586: Current learning rate: 0.00975\n",
      "2023-08-15 21:10:37.234469: train_loss -0.4627\n",
      "2023-08-15 21:10:37.235953: val_loss -0.3858\n",
      "2023-08-15 21:10:37.236142: Pseudo dice [0.5284]\n",
      "2023-08-15 21:10:37.236301: Epoch time: 128.57 s\n",
      "2023-08-15 21:10:39.680800: \n",
      "2023-08-15 21:10:39.681523: Epoch 29\n",
      "2023-08-15 21:10:39.681878: Current learning rate: 0.00974\n",
      "2023-08-15 21:13:00.605259: train_loss -0.4396\n",
      "2023-08-15 21:13:00.606737: val_loss -0.484\n",
      "2023-08-15 21:13:00.606852: Pseudo dice [0.6638]\n",
      "2023-08-15 21:13:00.606941: Epoch time: 140.93 s\n",
      "2023-08-15 21:13:00.607006: Yayy! New best EMA pseudo Dice: 0.5737\n",
      "2023-08-15 21:13:03.936289: \n",
      "2023-08-15 21:13:03.936435: Epoch 30\n",
      "2023-08-15 21:13:03.936552: Current learning rate: 0.00973\n",
      "2023-08-15 21:15:26.208798: train_loss -0.4526\n",
      "2023-08-15 21:15:26.210946: val_loss -0.4483\n",
      "2023-08-15 21:15:26.211109: Pseudo dice [0.5582]\n",
      "2023-08-15 21:15:26.211252: Epoch time: 142.27 s\n",
      "2023-08-15 21:15:28.676814: \n",
      "2023-08-15 21:15:28.676965: Epoch 31\n",
      "2023-08-15 21:15:28.677096: Current learning rate: 0.00972\n",
      "2023-08-15 21:17:51.495400: train_loss -0.4716\n",
      "2023-08-15 21:17:51.498552: val_loss -0.5116\n",
      "2023-08-15 21:17:51.498668: Pseudo dice [0.606]\n",
      "2023-08-15 21:17:51.498750: Epoch time: 142.82 s\n",
      "2023-08-15 21:17:51.498821: Yayy! New best EMA pseudo Dice: 0.5755\n",
      "2023-08-15 21:17:54.747065: \n",
      "2023-08-15 21:17:54.747211: Epoch 32\n",
      "2023-08-15 21:17:54.747365: Current learning rate: 0.00971\n",
      "2023-08-15 21:20:16.071100: train_loss -0.3994\n",
      "2023-08-15 21:20:16.073212: val_loss -0.4744\n",
      "2023-08-15 21:20:16.073306: Pseudo dice [0.5657]\n",
      "2023-08-15 21:20:16.073388: Epoch time: 141.33 s\n",
      "2023-08-15 21:20:18.243804: \n",
      "2023-08-15 21:20:18.244032: Epoch 33\n",
      "2023-08-15 21:20:18.244156: Current learning rate: 0.0097\n",
      "2023-08-15 21:22:36.169689: train_loss -0.4157\n",
      "2023-08-15 21:22:36.172286: val_loss -0.3955\n",
      "2023-08-15 21:22:36.172398: Pseudo dice [0.4754]\n",
      "2023-08-15 21:22:36.172484: Epoch time: 137.93 s\n",
      "2023-08-15 21:22:38.185635: \n",
      "2023-08-15 21:22:38.185791: Epoch 34\n",
      "2023-08-15 21:22:38.185901: Current learning rate: 0.00969\n",
      "2023-08-15 21:25:00.088095: train_loss -0.3851\n",
      "2023-08-15 21:25:00.100043: val_loss -0.4948\n",
      "2023-08-15 21:25:00.100195: Pseudo dice [0.6881]\n",
      "2023-08-15 21:25:00.100295: Epoch time: 141.9 s\n",
      "2023-08-15 21:25:00.100369: Yayy! New best EMA pseudo Dice: 0.577\n",
      "2023-08-15 21:25:03.522948: \n",
      "2023-08-15 21:25:03.523086: Epoch 35\n",
      "2023-08-15 21:25:03.523226: Current learning rate: 0.00968\n",
      "2023-08-15 21:27:25.531647: train_loss -0.4535\n",
      "2023-08-15 21:27:25.533559: val_loss -0.4782\n",
      "2023-08-15 21:27:25.533665: Pseudo dice [0.7051]\n",
      "2023-08-15 21:27:25.533748: Epoch time: 142.01 s\n",
      "2023-08-15 21:27:25.533817: Yayy! New best EMA pseudo Dice: 0.5898\n",
      "2023-08-15 21:27:29.761232: \n",
      "2023-08-15 21:27:29.761382: Epoch 36\n",
      "2023-08-15 21:27:29.761486: Current learning rate: 0.00968\n",
      "2023-08-15 21:29:46.824075: train_loss -0.4664\n",
      "2023-08-15 21:29:46.826195: val_loss -0.4929\n",
      "2023-08-15 21:29:46.826284: Pseudo dice [0.6477]\n",
      "2023-08-15 21:29:46.826365: Epoch time: 137.06 s\n",
      "2023-08-15 21:29:46.826425: Yayy! New best EMA pseudo Dice: 0.5956\n",
      "2023-08-15 21:29:50.287128: \n",
      "2023-08-15 21:29:50.287274: Epoch 37\n",
      "2023-08-15 21:29:50.287410: Current learning rate: 0.00967\n",
      "2023-08-15 21:32:17.804419: train_loss -0.4853\n",
      "2023-08-15 21:32:17.816015: val_loss -0.5224\n",
      "2023-08-15 21:32:17.816147: Pseudo dice [0.6996]\n",
      "2023-08-15 21:32:17.816245: Epoch time: 147.52 s\n",
      "2023-08-15 21:32:17.816314: Yayy! New best EMA pseudo Dice: 0.606\n",
      "2023-08-15 21:32:22.368573: \n",
      "2023-08-15 21:32:22.368744: Epoch 38\n",
      "2023-08-15 21:32:22.368903: Current learning rate: 0.00966\n",
      "2023-08-15 21:34:48.351681: train_loss -0.4928\n",
      "2023-08-15 21:34:48.352664: val_loss -0.4376\n",
      "2023-08-15 21:34:48.353084: Pseudo dice [0.7162]\n",
      "2023-08-15 21:34:48.353239: Epoch time: 145.98 s\n",
      "2023-08-15 21:34:48.353354: Yayy! New best EMA pseudo Dice: 0.617\n",
      "2023-08-15 21:34:52.280462: \n",
      "2023-08-15 21:34:52.280634: Epoch 39\n",
      "2023-08-15 21:34:52.280755: Current learning rate: 0.00965\n",
      "2023-08-15 21:37:09.665656: train_loss -0.5049\n",
      "2023-08-15 21:37:09.667088: val_loss -0.4478\n",
      "2023-08-15 21:37:09.667203: Pseudo dice [0.6473]\n",
      "2023-08-15 21:37:09.667296: Epoch time: 137.39 s\n",
      "2023-08-15 21:37:09.667362: Yayy! New best EMA pseudo Dice: 0.62\n",
      "2023-08-15 21:37:12.896083: \n",
      "2023-08-15 21:37:12.896393: Epoch 40\n",
      "2023-08-15 21:37:12.896503: Current learning rate: 0.00964\n",
      "2023-08-15 21:39:31.337630: train_loss -0.469\n",
      "2023-08-15 21:39:31.351660: val_loss -0.5776\n",
      "2023-08-15 21:39:31.351785: Pseudo dice [0.6686]\n",
      "2023-08-15 21:39:31.351883: Epoch time: 138.44 s\n",
      "2023-08-15 21:39:31.351951: Yayy! New best EMA pseudo Dice: 0.6249\n",
      "2023-08-15 21:39:35.967545: \n",
      "2023-08-15 21:39:35.967922: Epoch 41\n",
      "2023-08-15 21:39:35.968030: Current learning rate: 0.00963\n",
      "2023-08-15 21:41:59.792085: train_loss -0.4511\n",
      "2023-08-15 21:41:59.812050: val_loss -0.4928\n",
      "2023-08-15 21:41:59.812194: Pseudo dice [0.6566]\n",
      "2023-08-15 21:41:59.812289: Epoch time: 143.83 s\n",
      "2023-08-15 21:41:59.812355: Yayy! New best EMA pseudo Dice: 0.6281\n",
      "2023-08-15 21:42:02.957250: \n",
      "2023-08-15 21:42:02.957408: Epoch 42\n",
      "2023-08-15 21:42:02.957530: Current learning rate: 0.00962\n",
      "2023-08-15 21:44:31.497762: train_loss -0.491\n",
      "2023-08-15 21:44:31.507661: val_loss -0.4815\n",
      "2023-08-15 21:44:31.507787: Pseudo dice [0.7153]\n",
      "2023-08-15 21:44:31.507885: Epoch time: 148.54 s\n",
      "2023-08-15 21:44:31.507970: Yayy! New best EMA pseudo Dice: 0.6368\n",
      "2023-08-15 21:44:34.920725: \n",
      "2023-08-15 21:44:34.920894: Epoch 43\n",
      "2023-08-15 21:44:34.921011: Current learning rate: 0.00961\n",
      "2023-08-15 21:47:02.950843: train_loss -0.4889\n",
      "2023-08-15 21:47:02.968012: val_loss -0.4519\n",
      "2023-08-15 21:47:02.968154: Pseudo dice [0.6883]\n",
      "2023-08-15 21:47:02.968230: Epoch time: 148.03 s\n",
      "2023-08-15 21:47:02.968292: Yayy! New best EMA pseudo Dice: 0.642\n",
      "2023-08-15 21:47:06.813464: \n",
      "2023-08-15 21:47:06.813629: Epoch 44\n",
      "2023-08-15 21:47:06.813744: Current learning rate: 0.0096\n",
      "2023-08-15 21:49:28.213381: train_loss -0.4446\n",
      "2023-08-15 21:49:28.215367: val_loss -0.4707\n",
      "2023-08-15 21:49:28.215494: Pseudo dice [0.525]\n",
      "2023-08-15 21:49:28.215592: Epoch time: 141.4 s\n",
      "2023-08-15 21:49:30.347043: \n",
      "2023-08-15 21:49:30.347196: Epoch 45\n",
      "2023-08-15 21:49:30.347304: Current learning rate: 0.00959\n",
      "2023-08-15 21:51:55.324167: train_loss -0.4705\n",
      "2023-08-15 21:51:55.327245: val_loss -0.5195\n",
      "2023-08-15 21:51:55.327388: Pseudo dice [0.7181]\n",
      "2023-08-15 21:51:55.327482: Epoch time: 144.98 s\n",
      "2023-08-15 21:51:58.121634: \n",
      "2023-08-15 21:51:58.121845: Epoch 46\n",
      "2023-08-15 21:51:58.121976: Current learning rate: 0.00959\n",
      "2023-08-15 21:54:12.360554: train_loss -0.4901\n",
      "2023-08-15 21:54:12.364638: val_loss -0.4698\n",
      "2023-08-15 21:54:12.364789: Pseudo dice [0.6779]\n",
      "2023-08-15 21:54:12.364875: Epoch time: 134.24 s\n",
      "2023-08-15 21:54:12.364946: Yayy! New best EMA pseudo Dice: 0.6429\n",
      "2023-08-15 21:54:15.596895: \n",
      "2023-08-15 21:54:15.597437: Epoch 47\n",
      "2023-08-15 21:54:15.597643: Current learning rate: 0.00958\n",
      "2023-08-15 21:56:36.652677: train_loss -0.5136\n",
      "2023-08-15 21:56:36.655135: val_loss -0.4582\n",
      "2023-08-15 21:56:36.655359: Pseudo dice [0.555]\n",
      "2023-08-15 21:56:36.655448: Epoch time: 141.06 s\n",
      "2023-08-15 21:56:38.769085: \n",
      "2023-08-15 21:56:38.769459: Epoch 48\n",
      "2023-08-15 21:56:38.769659: Current learning rate: 0.00957\n",
      "2023-08-15 21:58:51.393444: train_loss -0.4965\n",
      "2023-08-15 21:58:51.396921: val_loss -0.5185\n",
      "2023-08-15 21:58:51.397381: Pseudo dice [0.7067]\n",
      "2023-08-15 21:58:51.397550: Epoch time: 132.63 s\n",
      "2023-08-15 21:58:53.488271: \n",
      "2023-08-15 21:58:53.488571: Epoch 49\n",
      "2023-08-15 21:58:53.488783: Current learning rate: 0.00956\n",
      "2023-08-15 22:01:20.960986: train_loss -0.4869\n",
      "2023-08-15 22:01:20.972117: val_loss -0.5234\n",
      "2023-08-15 22:01:20.972269: Pseudo dice [0.6933]\n",
      "2023-08-15 22:01:20.972356: Epoch time: 147.47 s\n",
      "2023-08-15 22:01:21.544039: Yayy! New best EMA pseudo Dice: 0.6466\n",
      "2023-08-15 22:01:24.682144: \n",
      "2023-08-15 22:01:24.682399: Epoch 50\n",
      "2023-08-15 22:01:24.682596: Current learning rate: 0.00955\n",
      "2023-08-15 22:03:43.400180: train_loss -0.4554\n",
      "2023-08-15 22:03:43.409133: val_loss -0.4782\n",
      "2023-08-15 22:03:43.409274: Pseudo dice [0.6328]\n",
      "2023-08-15 22:03:43.409351: Epoch time: 138.72 s\n",
      "2023-08-15 22:03:45.860808: \n",
      "2023-08-15 22:03:45.861183: Epoch 51\n",
      "2023-08-15 22:03:45.861298: Current learning rate: 0.00954\n",
      "2023-08-15 22:06:05.641044: train_loss -0.4849\n",
      "2023-08-15 22:06:05.641752: val_loss -0.5252\n",
      "2023-08-15 22:06:05.641904: Pseudo dice [0.7496]\n",
      "2023-08-15 22:06:05.642056: Epoch time: 139.78 s\n",
      "2023-08-15 22:06:05.642137: Yayy! New best EMA pseudo Dice: 0.6556\n",
      "2023-08-15 22:06:08.673829: \n",
      "2023-08-15 22:06:08.673957: Epoch 52\n",
      "2023-08-15 22:06:08.674074: Current learning rate: 0.00953\n",
      "2023-08-15 22:08:28.512383: train_loss -0.482\n",
      "2023-08-15 22:08:28.514390: val_loss -0.4829\n",
      "2023-08-15 22:08:28.514478: Pseudo dice [0.6586]\n",
      "2023-08-15 22:08:28.514554: Epoch time: 139.84 s\n",
      "2023-08-15 22:08:28.514615: Yayy! New best EMA pseudo Dice: 0.6559\n",
      "2023-08-15 22:08:31.769132: \n",
      "2023-08-15 22:08:31.769259: Epoch 53\n",
      "2023-08-15 22:08:31.769393: Current learning rate: 0.00952\n",
      "2023-08-15 22:10:51.539891: train_loss -0.4715\n",
      "2023-08-15 22:10:51.544046: val_loss -0.4975\n",
      "2023-08-15 22:10:51.544169: Pseudo dice [0.6562]\n",
      "2023-08-15 22:10:51.544260: Epoch time: 139.77 s\n",
      "2023-08-15 22:10:51.544326: Yayy! New best EMA pseudo Dice: 0.656\n",
      "2023-08-15 22:10:54.979357: \n",
      "2023-08-15 22:10:54.979628: Epoch 54\n",
      "2023-08-15 22:10:54.979741: Current learning rate: 0.00951\n",
      "2023-08-15 22:13:12.777428: train_loss -0.5041\n",
      "2023-08-15 22:13:12.779321: val_loss -0.5366\n",
      "2023-08-15 22:13:12.779446: Pseudo dice [0.6576]\n",
      "2023-08-15 22:13:12.779526: Epoch time: 137.8 s\n",
      "2023-08-15 22:13:12.779587: Yayy! New best EMA pseudo Dice: 0.6561\n",
      "2023-08-15 22:13:16.242237: \n",
      "2023-08-15 22:13:16.242409: Epoch 55\n",
      "2023-08-15 22:13:16.242529: Current learning rate: 0.0095\n",
      "2023-08-15 22:15:30.747097: train_loss -0.4764\n",
      "2023-08-15 22:15:30.751014: val_loss -0.5091\n",
      "2023-08-15 22:15:30.751230: Pseudo dice [0.7317]\n",
      "2023-08-15 22:15:30.751316: Epoch time: 134.51 s\n",
      "2023-08-15 22:15:30.751422: Yayy! New best EMA pseudo Dice: 0.6637\n",
      "2023-08-15 22:15:33.959844: \n",
      "2023-08-15 22:15:33.960129: Epoch 56\n",
      "2023-08-15 22:15:33.960347: Current learning rate: 0.00949\n",
      "2023-08-15 22:17:58.532742: train_loss -0.4658\n",
      "2023-08-15 22:17:58.535101: val_loss -0.5477\n",
      "2023-08-15 22:17:58.535237: Pseudo dice [0.6769]\n",
      "2023-08-15 22:17:58.535327: Epoch time: 144.57 s\n",
      "2023-08-15 22:17:58.535396: Yayy! New best EMA pseudo Dice: 0.665\n",
      "2023-08-15 22:18:01.831945: \n",
      "2023-08-15 22:18:01.832276: Epoch 57\n",
      "2023-08-15 22:18:01.832466: Current learning rate: 0.00949\n",
      "2023-08-15 22:20:15.335521: train_loss -0.5195\n",
      "2023-08-15 22:20:15.338590: val_loss -0.5118\n",
      "2023-08-15 22:20:15.338734: Pseudo dice [0.6701]\n",
      "2023-08-15 22:20:15.338815: Epoch time: 133.5 s\n",
      "2023-08-15 22:20:15.338884: Yayy! New best EMA pseudo Dice: 0.6655\n",
      "2023-08-15 22:20:18.446159: \n",
      "2023-08-15 22:20:18.446816: Epoch 58\n",
      "2023-08-15 22:20:18.447150: Current learning rate: 0.00948\n",
      "2023-08-15 22:22:33.246007: train_loss -0.5173\n",
      "2023-08-15 22:22:33.250294: val_loss -0.496\n",
      "2023-08-15 22:22:33.250429: Pseudo dice [0.6156]\n",
      "2023-08-15 22:22:33.250503: Epoch time: 134.8 s\n",
      "2023-08-15 22:22:36.340098: \n",
      "2023-08-15 22:22:36.340426: Epoch 59\n",
      "2023-08-15 22:22:36.340700: Current learning rate: 0.00947\n",
      "2023-08-15 22:24:48.584485: train_loss -0.5028\n",
      "2023-08-15 22:24:48.586608: val_loss -0.4828\n",
      "2023-08-15 22:24:48.586779: Pseudo dice [0.757]\n",
      "2023-08-15 22:24:48.586926: Epoch time: 132.25 s\n",
      "2023-08-15 22:24:48.587169: Yayy! New best EMA pseudo Dice: 0.6702\n",
      "2023-08-15 22:24:51.661294: \n",
      "2023-08-15 22:24:51.661709: Epoch 60\n",
      "2023-08-15 22:24:51.661900: Current learning rate: 0.00946\n",
      "2023-08-15 22:27:07.369080: train_loss -0.4775\n",
      "2023-08-15 22:27:07.376326: val_loss -0.5969\n",
      "2023-08-15 22:27:07.376624: Pseudo dice [0.7219]\n",
      "2023-08-15 22:27:07.376728: Epoch time: 135.71 s\n",
      "2023-08-15 22:27:07.376849: Yayy! New best EMA pseudo Dice: 0.6753\n",
      "2023-08-15 22:27:11.163742: \n",
      "2023-08-15 22:27:11.164020: Epoch 61\n",
      "2023-08-15 22:27:11.164186: Current learning rate: 0.00945\n",
      "2023-08-15 22:29:26.405354: train_loss -0.5353\n",
      "2023-08-15 22:29:26.406065: val_loss -0.46\n",
      "2023-08-15 22:29:26.406211: Pseudo dice [0.5498]\n",
      "2023-08-15 22:29:26.406358: Epoch time: 135.24 s\n",
      "2023-08-15 22:29:28.855164: \n",
      "2023-08-15 22:29:28.855497: Epoch 62\n",
      "2023-08-15 22:29:28.855670: Current learning rate: 0.00944\n",
      "2023-08-15 22:31:45.941403: train_loss -0.4487\n",
      "2023-08-15 22:31:45.942696: val_loss -0.5223\n",
      "2023-08-15 22:31:45.942778: Pseudo dice [0.6635]\n",
      "2023-08-15 22:31:45.942861: Epoch time: 137.09 s\n",
      "2023-08-15 22:31:47.917131: \n",
      "2023-08-15 22:31:47.917283: Epoch 63\n",
      "2023-08-15 22:31:47.917408: Current learning rate: 0.00943\n",
      "2023-08-15 22:34:10.336081: train_loss -0.481\n",
      "2023-08-15 22:34:10.338017: val_loss -0.4408\n",
      "2023-08-15 22:34:10.338130: Pseudo dice [0.5606]\n",
      "2023-08-15 22:34:10.338208: Epoch time: 142.42 s\n",
      "2023-08-15 22:34:12.675052: \n",
      "2023-08-15 22:34:12.675491: Epoch 64\n",
      "2023-08-15 22:34:12.675606: Current learning rate: 0.00942\n",
      "2023-08-15 22:36:36.113803: train_loss -0.4742\n",
      "2023-08-15 22:36:36.114495: val_loss -0.4786\n",
      "2023-08-15 22:36:36.114629: Pseudo dice [0.6522]\n",
      "2023-08-15 22:36:36.114702: Epoch time: 143.44 s\n",
      "2023-08-15 22:36:38.832336: \n",
      "2023-08-15 22:36:38.832485: Epoch 65\n",
      "2023-08-15 22:36:38.832601: Current learning rate: 0.00941\n",
      "2023-08-15 22:38:45.343411: train_loss -0.4928\n",
      "2023-08-15 22:38:45.346092: val_loss -0.5573\n",
      "2023-08-15 22:38:45.346341: Pseudo dice [0.6806]\n",
      "2023-08-15 22:38:45.346432: Epoch time: 126.51 s\n",
      "2023-08-15 22:38:48.083524: \n",
      "2023-08-15 22:38:48.083717: Epoch 66\n",
      "2023-08-15 22:38:48.083835: Current learning rate: 0.0094\n",
      "2023-08-15 22:41:12.282071: train_loss -0.48\n",
      "2023-08-15 22:41:12.283217: val_loss -0.4644\n",
      "2023-08-15 22:41:12.283328: Pseudo dice [0.5966]\n",
      "2023-08-15 22:41:12.283428: Epoch time: 144.2 s\n",
      "2023-08-15 22:41:14.144183: \n",
      "2023-08-15 22:41:14.144465: Epoch 67\n",
      "2023-08-15 22:41:14.144577: Current learning rate: 0.00939\n",
      "2023-08-15 22:43:38.940271: train_loss -0.4919\n",
      "2023-08-15 22:43:38.956024: val_loss -0.485\n",
      "2023-08-15 22:43:38.956162: Pseudo dice [0.4871]\n",
      "2023-08-15 22:43:38.956239: Epoch time: 144.8 s\n",
      "2023-08-15 22:43:41.310677: \n",
      "2023-08-15 22:43:41.310825: Epoch 68\n",
      "2023-08-15 22:43:41.311155: Current learning rate: 0.00939\n",
      "2023-08-15 22:46:03.964815: train_loss -0.5033\n",
      "2023-08-15 22:46:03.966877: val_loss -0.523\n",
      "2023-08-15 22:46:03.967139: Pseudo dice [0.6357]\n",
      "2023-08-15 22:46:03.967299: Epoch time: 142.66 s\n",
      "2023-08-15 22:46:06.851039: \n",
      "2023-08-15 22:46:06.851190: Epoch 69\n",
      "2023-08-15 22:46:06.851301: Current learning rate: 0.00938\n",
      "2023-08-15 22:48:28.007492: train_loss -0.4771\n",
      "2023-08-15 22:48:28.009066: val_loss -0.4207\n",
      "2023-08-15 22:48:28.009175: Pseudo dice [0.5996]\n",
      "2023-08-15 22:48:28.009256: Epoch time: 141.16 s\n",
      "2023-08-15 22:48:31.051567: \n",
      "2023-08-15 22:48:31.051703: Epoch 70\n",
      "2023-08-15 22:48:31.051815: Current learning rate: 0.00937\n",
      "2023-08-15 22:50:47.645580: train_loss -0.4733\n",
      "2023-08-15 22:50:47.647643: val_loss -0.4805\n",
      "2023-08-15 22:50:47.647759: Pseudo dice [0.6236]\n",
      "2023-08-15 22:50:47.647849: Epoch time: 136.6 s\n",
      "2023-08-15 22:50:49.714549: \n",
      "2023-08-15 22:50:49.714675: Epoch 71\n",
      "2023-08-15 22:50:49.714786: Current learning rate: 0.00936\n",
      "2023-08-15 22:53:08.303305: train_loss -0.4754\n",
      "2023-08-15 22:53:08.304807: val_loss -0.5268\n",
      "2023-08-15 22:53:08.304904: Pseudo dice [0.6466]\n",
      "2023-08-15 22:53:08.304985: Epoch time: 138.59 s\n",
      "2023-08-15 22:53:10.504845: \n",
      "2023-08-15 22:53:10.505275: Epoch 72\n",
      "2023-08-15 22:53:10.505516: Current learning rate: 0.00935\n",
      "2023-08-15 22:55:21.146902: train_loss -0.4604\n",
      "2023-08-15 22:55:21.149253: val_loss -0.5283\n",
      "2023-08-15 22:55:21.149368: Pseudo dice [0.6549]\n",
      "2023-08-15 22:55:21.149455: Epoch time: 130.64 s\n",
      "2023-08-15 22:55:23.087067: \n",
      "2023-08-15 22:55:23.087241: Epoch 73\n",
      "2023-08-15 22:55:23.087405: Current learning rate: 0.00934\n",
      "2023-08-15 22:57:43.783575: train_loss -0.4733\n",
      "2023-08-15 22:57:43.788978: val_loss -0.5462\n",
      "2023-08-15 22:57:43.789227: Pseudo dice [0.7366]\n",
      "2023-08-15 22:57:43.789325: Epoch time: 140.7 s\n",
      "2023-08-15 22:57:46.706351: \n",
      "2023-08-15 22:57:46.706541: Epoch 74\n",
      "2023-08-15 22:57:46.706651: Current learning rate: 0.00933\n",
      "2023-08-15 23:00:06.272624: train_loss -0.5019\n",
      "2023-08-15 23:00:06.274330: val_loss -0.4834\n",
      "2023-08-15 23:00:06.274434: Pseudo dice [0.6779]\n",
      "2023-08-15 23:00:06.274523: Epoch time: 139.57 s\n",
      "2023-08-15 23:00:08.340241: \n",
      "2023-08-15 23:00:08.340571: Epoch 75\n",
      "2023-08-15 23:00:08.340731: Current learning rate: 0.00932\n",
      "2023-08-15 23:02:18.823322: train_loss -0.5311\n",
      "2023-08-15 23:02:18.827674: val_loss -0.4303\n",
      "2023-08-15 23:02:18.827825: Pseudo dice [0.5793]\n",
      "2023-08-15 23:02:18.827925: Epoch time: 130.48 s\n",
      "2023-08-15 23:02:21.129292: \n",
      "2023-08-15 23:02:21.129568: Epoch 76\n",
      "2023-08-15 23:02:21.129716: Current learning rate: 0.00931\n",
      "2023-08-15 23:04:36.239464: train_loss -0.5076\n",
      "2023-08-15 23:04:36.260130: val_loss -0.4608\n",
      "2023-08-15 23:04:36.260293: Pseudo dice [0.6764]\n",
      "2023-08-15 23:04:36.260385: Epoch time: 135.11 s\n",
      "2023-08-15 23:04:38.289238: \n",
      "2023-08-15 23:04:38.289407: Epoch 77\n",
      "2023-08-15 23:04:38.289633: Current learning rate: 0.0093\n",
      "2023-08-15 23:06:47.752051: train_loss -0.5242\n",
      "2023-08-15 23:06:47.752644: val_loss -0.5091\n",
      "2023-08-15 23:06:47.752759: Pseudo dice [0.6072]\n",
      "2023-08-15 23:06:47.752842: Epoch time: 129.46 s\n",
      "2023-08-15 23:06:50.614153: \n",
      "2023-08-15 23:06:50.614326: Epoch 78\n",
      "2023-08-15 23:06:50.614440: Current learning rate: 0.0093\n",
      "2023-08-15 23:09:13.808753: train_loss -0.5373\n",
      "2023-08-15 23:09:13.818777: val_loss -0.6094\n",
      "2023-08-15 23:09:13.818995: Pseudo dice [0.7858]\n",
      "2023-08-15 23:09:13.819111: Epoch time: 143.2 s\n",
      "2023-08-15 23:09:16.332253: \n",
      "2023-08-15 23:09:16.332426: Epoch 79\n",
      "2023-08-15 23:09:16.332544: Current learning rate: 0.00929\n",
      "2023-08-15 23:11:30.087436: train_loss -0.4819\n",
      "2023-08-15 23:11:30.103505: val_loss -0.4719\n",
      "2023-08-15 23:11:30.104150: Pseudo dice [0.5292]\n",
      "2023-08-15 23:11:30.104679: Epoch time: 133.76 s\n",
      "2023-08-15 23:11:33.680360: \n",
      "2023-08-15 23:11:33.680538: Epoch 80\n",
      "2023-08-15 23:11:33.680644: Current learning rate: 0.00928\n",
      "2023-08-15 23:13:53.188802: train_loss -0.4784\n",
      "2023-08-15 23:13:53.204005: val_loss -0.5559\n",
      "2023-08-15 23:13:53.204142: Pseudo dice [0.6111]\n",
      "2023-08-15 23:13:53.204222: Epoch time: 139.51 s\n",
      "2023-08-15 23:13:55.621932: \n",
      "2023-08-15 23:13:55.622121: Epoch 81\n",
      "2023-08-15 23:13:55.622229: Current learning rate: 0.00927\n",
      "2023-08-15 23:16:10.200795: train_loss -0.5438\n",
      "2023-08-15 23:16:10.205173: val_loss -0.4616\n",
      "2023-08-15 23:16:10.205274: Pseudo dice [0.5142]\n",
      "2023-08-15 23:16:10.205360: Epoch time: 134.58 s\n",
      "2023-08-15 23:16:12.316720: \n",
      "2023-08-15 23:16:12.316863: Epoch 82\n",
      "2023-08-15 23:16:12.316967: Current learning rate: 0.00926\n",
      "2023-08-15 23:18:34.857447: train_loss -0.4871\n",
      "2023-08-15 23:18:34.858692: val_loss -0.5772\n",
      "2023-08-15 23:18:34.858829: Pseudo dice [0.6614]\n",
      "2023-08-15 23:18:34.858911: Epoch time: 142.54 s\n",
      "2023-08-15 23:18:37.649923: \n",
      "2023-08-15 23:18:37.650141: Epoch 83\n",
      "2023-08-15 23:18:37.650310: Current learning rate: 0.00925\n",
      "2023-08-15 23:21:02.151974: train_loss -0.516\n",
      "2023-08-15 23:21:02.155432: val_loss -0.4799\n",
      "2023-08-15 23:21:02.155564: Pseudo dice [0.7072]\n",
      "2023-08-15 23:21:02.155641: Epoch time: 144.5 s\n",
      "2023-08-15 23:21:06.247007: \n",
      "2023-08-15 23:21:06.247150: Epoch 84\n",
      "2023-08-15 23:21:06.247284: Current learning rate: 0.00924\n",
      "2023-08-15 23:23:33.611369: train_loss -0.5183\n",
      "2023-08-15 23:23:33.612993: val_loss -0.5244\n",
      "2023-08-15 23:23:33.613098: Pseudo dice [0.5757]\n",
      "2023-08-15 23:23:33.613183: Epoch time: 147.37 s\n",
      "2023-08-15 23:23:35.583404: \n",
      "2023-08-15 23:23:35.583545: Epoch 85\n",
      "2023-08-15 23:23:35.583658: Current learning rate: 0.00923\n",
      "2023-08-15 23:25:51.483865: train_loss -0.5337\n",
      "2023-08-15 23:25:51.485250: val_loss -0.4207\n",
      "2023-08-15 23:25:51.485360: Pseudo dice [0.5904]\n",
      "2023-08-15 23:25:51.485444: Epoch time: 135.9 s\n",
      "2023-08-15 23:25:53.416213: \n",
      "2023-08-15 23:25:53.416498: Epoch 86\n",
      "2023-08-15 23:25:53.416618: Current learning rate: 0.00922\n",
      "2023-08-15 23:28:07.545045: train_loss -0.5343\n",
      "2023-08-15 23:28:07.546857: val_loss -0.5926\n",
      "2023-08-15 23:28:07.546990: Pseudo dice [0.7137]\n",
      "2023-08-15 23:28:07.547081: Epoch time: 134.13 s\n",
      "2023-08-15 23:28:09.461426: \n",
      "2023-08-15 23:28:09.461612: Epoch 87\n",
      "2023-08-15 23:28:09.461748: Current learning rate: 0.00921\n",
      "2023-08-15 23:30:25.183741: train_loss -0.5417\n",
      "2023-08-15 23:30:25.186315: val_loss -0.4852\n",
      "2023-08-15 23:30:25.186481: Pseudo dice [0.584]\n",
      "2023-08-15 23:30:25.186631: Epoch time: 135.72 s\n",
      "2023-08-15 23:30:27.724123: \n",
      "2023-08-15 23:30:27.724492: Epoch 88\n",
      "2023-08-15 23:30:27.724726: Current learning rate: 0.0092\n",
      "2023-08-15 23:32:42.812126: train_loss -0.5294\n",
      "2023-08-15 23:32:42.815610: val_loss -0.5376\n",
      "2023-08-15 23:32:42.815846: Pseudo dice [0.6208]\n",
      "2023-08-15 23:32:42.816013: Epoch time: 135.09 s\n",
      "2023-08-15 23:32:45.127120: \n",
      "2023-08-15 23:32:45.127285: Epoch 89\n",
      "2023-08-15 23:32:45.127383: Current learning rate: 0.0092\n",
      "2023-08-15 23:35:02.679814: train_loss -0.4939\n",
      "2023-08-15 23:35:02.681000: val_loss -0.4392\n",
      "2023-08-15 23:35:02.681101: Pseudo dice [0.6002]\n",
      "2023-08-15 23:35:02.681183: Epoch time: 137.55 s\n",
      "2023-08-15 23:35:04.542010: \n",
      "2023-08-15 23:35:04.542252: Epoch 90\n",
      "2023-08-15 23:35:04.542354: Current learning rate: 0.00919\n",
      "2023-08-15 23:37:10.757997: train_loss -0.5127\n",
      "2023-08-15 23:37:10.758795: val_loss -0.549\n",
      "2023-08-15 23:37:10.758883: Pseudo dice [0.6528]\n",
      "2023-08-15 23:37:10.758958: Epoch time: 126.22 s\n",
      "2023-08-15 23:37:13.841050: \n",
      "2023-08-15 23:37:13.841352: Epoch 91\n",
      "2023-08-15 23:37:13.841520: Current learning rate: 0.00918\n",
      "2023-08-15 23:39:26.920992: train_loss -0.5388\n",
      "2023-08-15 23:39:26.923940: val_loss -0.5529\n",
      "2023-08-15 23:39:26.924042: Pseudo dice [0.6065]\n",
      "2023-08-15 23:39:26.924117: Epoch time: 133.08 s\n",
      "2023-08-15 23:39:28.771037: \n",
      "2023-08-15 23:39:28.771320: Epoch 92\n",
      "2023-08-15 23:39:28.771450: Current learning rate: 0.00917\n",
      "2023-08-15 23:41:46.111794: train_loss -0.5183\n",
      "2023-08-15 23:41:46.112544: val_loss -0.4172\n",
      "2023-08-15 23:41:46.112652: Pseudo dice [0.5308]\n",
      "2023-08-15 23:41:46.113120: Epoch time: 137.34 s\n",
      "2023-08-15 23:41:47.959416: \n",
      "2023-08-15 23:41:47.959598: Epoch 93\n",
      "2023-08-15 23:41:47.959699: Current learning rate: 0.00916\n",
      "2023-08-15 23:44:03.228407: train_loss -0.5056\n",
      "2023-08-15 23:44:03.230344: val_loss -0.4658\n",
      "2023-08-15 23:44:03.230492: Pseudo dice [0.6059]\n",
      "2023-08-15 23:44:03.230574: Epoch time: 135.27 s\n",
      "2023-08-15 23:44:05.849421: \n",
      "2023-08-15 23:44:05.849790: Epoch 94\n",
      "2023-08-15 23:44:05.850142: Current learning rate: 0.00915\n",
      "2023-08-15 23:46:22.199028: train_loss -0.5117\n",
      "2023-08-15 23:46:22.200531: val_loss -0.4974\n",
      "2023-08-15 23:46:22.200695: Pseudo dice [0.7301]\n",
      "2023-08-15 23:46:22.200789: Epoch time: 136.35 s\n",
      "2023-08-15 23:46:25.043267: \n",
      "2023-08-15 23:46:25.043877: Epoch 95\n",
      "2023-08-15 23:46:25.044099: Current learning rate: 0.00914\n",
      "2023-08-15 23:48:40.276289: train_loss -0.5208\n",
      "2023-08-15 23:48:40.278602: val_loss -0.4548\n",
      "2023-08-15 23:48:40.278854: Pseudo dice [0.6539]\n",
      "2023-08-15 23:48:40.279054: Epoch time: 135.23 s\n",
      "2023-08-15 23:48:42.232792: \n",
      "2023-08-15 23:48:42.233014: Epoch 96\n",
      "2023-08-15 23:48:42.233129: Current learning rate: 0.00913\n",
      "2023-08-15 23:51:01.922412: train_loss -0.5227\n",
      "2023-08-15 23:51:01.924674: val_loss -0.5736\n",
      "2023-08-15 23:51:01.924767: Pseudo dice [0.7196]\n",
      "2023-08-15 23:51:01.924907: Epoch time: 139.69 s\n",
      "2023-08-15 23:51:03.728560: \n",
      "2023-08-15 23:51:03.728902: Epoch 97\n",
      "2023-08-15 23:51:03.729017: Current learning rate: 0.00912\n",
      "2023-08-15 23:53:21.178496: train_loss -0.5399\n",
      "2023-08-15 23:53:21.179336: val_loss -0.5707\n",
      "2023-08-15 23:53:21.179429: Pseudo dice [0.7114]\n",
      "2023-08-15 23:53:21.179514: Epoch time: 137.45 s\n",
      "2023-08-15 23:53:24.086279: \n",
      "2023-08-15 23:53:24.086512: Epoch 98\n",
      "2023-08-15 23:53:24.086630: Current learning rate: 0.00911\n",
      "2023-08-15 23:55:34.901158: train_loss -0.5287\n",
      "2023-08-15 23:55:34.902507: val_loss -0.465\n",
      "2023-08-15 23:55:34.902592: Pseudo dice [0.625]\n",
      "2023-08-15 23:55:34.902664: Epoch time: 130.82 s\n",
      "2023-08-15 23:55:36.875687: \n",
      "2023-08-15 23:55:36.875824: Epoch 99\n",
      "2023-08-15 23:55:36.875965: Current learning rate: 0.0091\n",
      "2023-08-15 23:57:47.193432: train_loss -0.526\n",
      "2023-08-15 23:57:47.196074: val_loss -0.591\n",
      "2023-08-15 23:57:47.197167: Pseudo dice [0.7707]\n",
      "2023-08-15 23:57:47.197401: Epoch time: 130.32 s\n",
      "2023-08-15 23:57:50.487493: \n",
      "2023-08-15 23:57:50.487771: Epoch 100\n",
      "2023-08-15 23:57:50.488027: Current learning rate: 0.0091\n",
      "2023-08-16 00:00:05.016362: train_loss -0.5474\n",
      "2023-08-16 00:00:05.017371: val_loss -0.4853\n",
      "2023-08-16 00:00:05.017472: Pseudo dice [0.6709]\n",
      "2023-08-16 00:00:05.017558: Epoch time: 134.53 s\n",
      "2023-08-16 00:00:07.062076: \n",
      "2023-08-16 00:00:07.062235: Epoch 101\n",
      "2023-08-16 00:00:07.062368: Current learning rate: 0.00909\n",
      "2023-08-16 00:02:22.188323: train_loss -0.5799\n",
      "2023-08-16 00:02:22.189302: val_loss -0.5792\n",
      "2023-08-16 00:02:22.189432: Pseudo dice [0.7911]\n",
      "2023-08-16 00:02:22.189513: Epoch time: 135.13 s\n",
      "2023-08-16 00:02:24.601009: \n",
      "2023-08-16 00:02:24.601161: Epoch 102\n",
      "2023-08-16 00:02:24.601273: Current learning rate: 0.00908\n",
      "2023-08-16 00:04:44.915723: train_loss -0.5283\n",
      "2023-08-16 00:04:44.922719: val_loss -0.514\n",
      "2023-08-16 00:04:44.922848: Pseudo dice [0.6362]\n",
      "2023-08-16 00:04:44.922924: Epoch time: 140.32 s\n",
      "2023-08-16 00:04:47.191279: \n",
      "2023-08-16 00:04:47.191443: Epoch 103\n",
      "2023-08-16 00:04:47.191550: Current learning rate: 0.00907\n",
      "2023-08-16 00:07:22.527148: train_loss -0.538\n",
      "2023-08-16 00:07:22.529131: val_loss -0.48\n",
      "2023-08-16 00:07:22.529314: Pseudo dice [0.6237]\n",
      "2023-08-16 00:07:22.529413: Epoch time: 155.34 s\n",
      "2023-08-16 00:07:25.423919: \n",
      "2023-08-16 00:07:25.424314: Epoch 104\n",
      "2023-08-16 00:07:25.424421: Current learning rate: 0.00906\n",
      "2023-08-16 00:09:45.577463: train_loss -0.5477\n",
      "2023-08-16 00:09:45.588005: val_loss -0.5434\n",
      "2023-08-16 00:09:45.588160: Pseudo dice [0.7094]\n",
      "2023-08-16 00:09:45.588244: Epoch time: 140.15 s\n",
      "2023-08-16 00:09:49.650375: \n",
      "2023-08-16 00:09:49.650696: Epoch 105\n",
      "2023-08-16 00:09:49.650899: Current learning rate: 0.00905\n",
      "2023-08-16 00:12:15.694422: train_loss -0.5187\n",
      "2023-08-16 00:12:15.695182: val_loss -0.5237\n",
      "2023-08-16 00:12:15.695301: Pseudo dice [0.7648]\n",
      "2023-08-16 00:12:15.695386: Epoch time: 146.05 s\n",
      "2023-08-16 00:12:15.695449: Yayy! New best EMA pseudo Dice: 0.6779\n",
      "2023-08-16 00:12:18.887963: \n",
      "2023-08-16 00:12:18.888105: Epoch 106\n",
      "2023-08-16 00:12:18.888209: Current learning rate: 0.00904\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/nnUNetv2_train\", line 8, in <module>\n",
      "    sys.exit(run_training_entry())\n",
      "  File \"/home/nnUNet/nnunetv2/run/run_training.py\", line 268, in run_training_entry\n",
      "    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,\n",
      "  File \"/home/nnUNet/nnunetv2/run/run_training.py\", line 204, in run_training\n",
      "    nnunet_trainer.run_training()\n",
      "  File \"/home/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\", line 1235, in run_training\n",
      "    train_outputs.append(self.train_step(next(self.dataloader_train)))\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 196, in __next__\n",
      "    item = self.__get_next_item()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 188, in __get_next_item\n",
      "    sleep(self.wait_time)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_train 013 3d_fullres 0 --npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cf1d95e-3e97-4e01-b9c0-16a66fdc07fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 3d_fullres\n",
      " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [326.0, 400.0, 400.0], 'spacing': [3.0, 2.0364201068878174, 2.0364201068878174], 'normalization_schemes': ['ZScoreNormalization', 'CTNormalization'], 'use_mask_for_norm': [False, False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'num_pool_per_axis': [5, 5, 5], 'pool_op_kernel_sizes': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'unet_max_num_features': 320, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset013_PETCTDB', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [3.0, 2.0364201068878174, 2.0364201068878174], 'original_median_shape_after_transp': [326, 400, 400], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 167.9757537841797, 'mean': 5.435083991534125, 'median': 3.9277126789093018, 'min': 0.09483639150857925, 'percentile_00_5': 1.1182502508163452, 'percentile_99_5': 26.928308486938477, 'std': 4.513973614205279}, '1': {'max': 3412.23974609375, 'mean': 0.09971613855090386, 'median': 49.86198425292969, 'min': -1464.62890625, 'percentile_00_5': -830.406982421875, 'percentile_99_5': 714.96435546875, 'std': 228.73367229561458}}} \n",
      "\n",
      "2023-08-16 00:19:46.790699: unpacking dataset...\n",
      "2023-08-16 00:19:50.956308: unpacking done...\n",
      "2023-08-16 00:19:50.957971: do_dummy_2d_data_aug: False\n",
      "2023-08-16 00:19:50.960155: Using splits from existing split file: nnUNet_preprocessed/Dataset013_PETCTDB/splits_final.json\n",
      "2023-08-16 00:19:50.960673: The split file contains 5 splits.\n",
      "2023-08-16 00:19:50.960788: Desired fold for training: 0\n",
      "2023-08-16 00:19:50.960888: This split has 87 training and 22 validation cases.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/onnx/symbolic_helper.py:1466: UserWarning: ONNX export mode is set to TrainingMode.EVAL, but operator 'instance_norm' is set to train=True. Exporting with train=True.\n",
      "  warnings.warn(\n",
      "2023-08-16 00:19:55.017080: Unable to plot network architecture:\n",
      "2023-08-16 00:19:55.017164: failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH\n",
      "2023-08-16 00:19:55.058230: \n",
      "2023-08-16 00:19:55.058302: Epoch 0\n",
      "2023-08-16 00:19:55.058457: Current learning rate: 0.01\n",
      "using pin_memory on device 0\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/nnUNetv2_train\", line 8, in <module>\n",
      "    sys.exit(run_training_entry())\n",
      "  File \"/home/nnUNet/nnunetv2/run/run_training.py\", line 268, in run_training_entry\n",
      "    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,\n",
      "  File \"/home/nnUNet/nnunetv2/run/run_training.py\", line 204, in run_training\n",
      "    nnunet_trainer.run_training()\n",
      "  File \"/home/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\", line 1235, in run_training\n",
      "    train_outputs.append(self.train_step(next(self.dataloader_train)))\n",
      "  File \"/home/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\", line 883, in train_step\n",
      "    torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/utils/clip_grad.py\", line 76, in clip_grad_norm_\n",
      "    torch._foreach_mul_(grads, clip_coef_clamped.to(device))  # type: ignore[call-overload]\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_train 013 3d_fullres 0 --npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24a8b550-2570-448e-ac79-558c16d8177e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 3d_fullres\n",
      " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [326.0, 400.0, 400.0], 'spacing': [3.0, 2.0364201068878174, 2.0364201068878174], 'normalization_schemes': ['ZScoreNormalization', 'CTNormalization'], 'use_mask_for_norm': [False, False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'num_pool_per_axis': [5, 5, 5], 'pool_op_kernel_sizes': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'unet_max_num_features': 320, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset013_PETCTDB', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [3.0, 2.0364201068878174, 2.0364201068878174], 'original_median_shape_after_transp': [326, 400, 400], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 167.9757537841797, 'mean': 5.435083991534125, 'median': 3.9277126789093018, 'min': 0.09483639150857925, 'percentile_00_5': 1.1182502508163452, 'percentile_99_5': 26.928308486938477, 'std': 4.513973614205279}, '1': {'max': 3412.23974609375, 'mean': 0.09971613855090386, 'median': 49.86198425292969, 'min': -1464.62890625, 'percentile_00_5': -830.406982421875, 'percentile_99_5': 714.96435546875, 'std': 228.73367229561458}}} \n",
      "\n",
      "2023-08-16 00:28:01.503837: unpacking dataset...\n",
      "2023-08-16 00:28:05.495059: unpacking done...\n",
      "2023-08-16 00:28:05.496696: do_dummy_2d_data_aug: False\n",
      "2023-08-16 00:28:05.498763: Using splits from existing split file: nnUNet_preprocessed/Dataset013_PETCTDB/splits_final.json\n",
      "2023-08-16 00:28:05.499222: The split file contains 5 splits.\n",
      "2023-08-16 00:28:05.499333: Desired fold for training: 1\n",
      "2023-08-16 00:28:05.499433: This split has 87 training and 22 validation cases.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/onnx/symbolic_helper.py:1466: UserWarning: ONNX export mode is set to TrainingMode.EVAL, but operator 'instance_norm' is set to train=True. Exporting with train=True.\n",
      "  warnings.warn(\n",
      "2023-08-16 00:28:09.457156: Unable to plot network architecture:\n",
      "2023-08-16 00:28:09.457250: failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH\n",
      "2023-08-16 00:28:09.497806: \n",
      "2023-08-16 00:28:09.497875: Epoch 0\n",
      "2023-08-16 00:28:09.498012: Current learning rate: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2023-08-16 00:30:48.885000: train_loss -0.1162\n",
      "2023-08-16 00:30:48.896220: val_loss -0.1135\n",
      "2023-08-16 00:30:48.896329: Pseudo dice [0.2304]\n",
      "2023-08-16 00:30:48.896420: Epoch time: 159.39 s\n",
      "2023-08-16 00:30:48.896501: Yayy! New best EMA pseudo Dice: 0.2304\n",
      "2023-08-16 00:30:51.230612: \n",
      "2023-08-16 00:30:51.230910: Epoch 1\n",
      "2023-08-16 00:30:51.231120: Current learning rate: 0.00993\n",
      "2023-08-16 00:33:09.516009: train_loss -0.2233\n",
      "2023-08-16 00:33:09.516864: val_loss -0.0992\n",
      "2023-08-16 00:33:09.516961: Pseudo dice [0.1525]\n",
      "2023-08-16 00:33:09.517042: Epoch time: 138.29 s\n",
      "2023-08-16 00:33:13.786608: \n",
      "2023-08-16 00:33:13.786759: Epoch 2\n",
      "2023-08-16 00:33:13.786877: Current learning rate: 0.00986\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/nnUNetv2_train\", line 8, in <module>\n",
      "    sys.exit(run_training_entry())\n",
      "  File \"/home/nnUNet/nnunetv2/run/run_training.py\", line 268, in run_training_entry\n",
      "    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,\n",
      "  File \"/home/nnUNet/nnunetv2/run/run_training.py\", line 204, in run_training\n",
      "    nnunet_trainer.run_training()\n",
      "  File \"/home/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\", line 1235, in run_training\n",
      "    train_outputs.append(self.train_step(next(self.dataloader_train)))\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 196, in __next__\n",
      "    item = self.__get_next_item()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 188, in __get_next_item\n",
      "    sleep(self.wait_time)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_train 013 3d_fullres 1 --npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "706ff48f-cba1-4a34-94dd-86c35551f40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "There are 2 cases in the source folder\n",
      "I am process 0 out of 1 (max process ID is 0, we start counting with 0!)\n",
      "There are 2 cases that I would like to predict\n",
      "\n",
      "Predicting patient79:\n",
      "perform_everything_on_gpu: True\n",
      "100%|█████████████████████████████████████████| 180/180 [00:44<00:00,  4.07it/s]\n",
      "Prediction done, transferring to CPU if needed\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with patient79\n",
      "\n",
      "Predicting patient80:\n",
      "perform_everything_on_gpu: True\n",
      "100%|█████████████████████████████████████████| 180/180 [00:42<00:00,  4.22it/s]\n",
      "Prediction done, transferring to CPU if needed\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with patient80\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_predict -i data/Dataset013_PETCTDB/imagesTs -o RESULTS_FOLDER/predict -d 013 -c 3d_fullres -f 0 --save_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd834dda-c579-4a76-8035-f860caf2f1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/nnUNetv2_find_best_configuration\", line 8, in <module>\n",
      "    sys.exit(find_best_configuration_entry_point())\n",
      "  File \"/home/nnUNet/nnunetv2/evaluation/find_best_configuration.py\", line 295, in find_best_configuration_entry_point\n",
      "    find_best_configuration(dataset_name, model_dict, allow_ensembling=not args.disable_ensembling,\n",
      "  File \"/home/nnUNet/nnunetv2/evaluation/find_best_configuration.py\", line 100, in find_best_configuration\n",
      "    accumulate_cv_results(output_folder, merged_output_folder, folds, num_processes, overwrite)\n",
      "  File \"/home/nnUNet/nnunetv2/evaluation/accumulate_cv_results.py\", line 36, in accumulate_cv_results\n",
      "    raise RuntimeError(f\"fold {f} of model {trained_model_folder} is missing. Please train it!\")\n",
      "RuntimeError: fold 0 of model result_folder/Dataset013_PETCTDB/nnUNetTrainer__nnUNetPlans__3d_fullres is missing. Please train it!\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_find_best_configuration 013 -c 3d_fullres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c478f3f-c902-43a4-b020-e05b5be6ea6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 3d_fullres\n",
      " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [326.0, 400.0, 400.0], 'spacing': [3.0, 2.0364201068878174, 2.0364201068878174], 'normalization_schemes': ['ZScoreNormalization', 'CTNormalization'], 'use_mask_for_norm': [False, False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'num_pool_per_axis': [5, 5, 5], 'pool_op_kernel_sizes': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'unet_max_num_features': 320, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset013_PETCTDB', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [3.0, 2.0364201068878174, 2.0364201068878174], 'original_median_shape_after_transp': [326, 400, 400], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 167.9757537841797, 'mean': 5.435083991534125, 'median': 3.9277126789093018, 'min': 0.09483639150857925, 'percentile_00_5': 1.1182502508163452, 'percentile_99_5': 26.928308486938477, 'std': 4.513973614205279}, '1': {'max': 3412.23974609375, 'mean': 0.09971613855090386, 'median': 49.86198425292969, 'min': -1464.62890625, 'percentile_00_5': -830.406982421875, 'percentile_99_5': 714.96435546875, 'std': 228.73367229561458}}} \n",
      "\n",
      "2023-08-16 00:41:29.784639: unpacking dataset...\n",
      "2023-08-16 00:41:33.864604: unpacking done...\n",
      "2023-08-16 00:41:33.865302: do_dummy_2d_data_aug: False\n",
      "2023-08-16 00:41:33.866120: Using splits from existing split file: nnUNet_preprocessed/Dataset013_PETCTDB/splits_final.json\n",
      "2023-08-16 00:41:33.866288: The split file contains 5 splits.\n",
      "2023-08-16 00:41:33.866327: Desired fold for training: 1\n",
      "2023-08-16 00:41:33.866361: This split has 87 training and 22 validation cases.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/onnx/symbolic_helper.py:1466: UserWarning: ONNX export mode is set to TrainingMode.EVAL, but operator 'instance_norm' is set to train=True. Exporting with train=True.\n",
      "  warnings.warn(\n",
      "2023-08-16 00:41:38.268152: Unable to plot network architecture:\n",
      "2023-08-16 00:41:38.268271: failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH\n",
      "2023-08-16 00:41:38.309865: \n",
      "2023-08-16 00:41:38.309938: Epoch 0\n",
      "2023-08-16 00:41:38.310118: Current learning rate: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2023-08-16 00:44:15.976696: train_loss -0.1281\n",
      "2023-08-16 00:44:15.979546: val_loss -0.1199\n",
      "2023-08-16 00:44:15.979685: Pseudo dice [0.2228]\n",
      "2023-08-16 00:44:15.979916: Epoch time: 157.67 s\n",
      "2023-08-16 00:44:15.980188: Yayy! New best EMA pseudo Dice: 0.2228\n",
      "2023-08-16 00:44:19.053895: \n",
      "2023-08-16 00:44:19.054036: Epoch 1\n",
      "2023-08-16 00:44:19.054233: Current learning rate: 0.00993\n",
      "2023-08-16 00:46:37.312467: train_loss -0.2684\n",
      "2023-08-16 00:46:37.313381: val_loss -0.2713\n",
      "2023-08-16 00:46:37.313479: Pseudo dice [0.3387]\n",
      "2023-08-16 00:46:37.313561: Epoch time: 138.26 s\n",
      "2023-08-16 00:46:37.313623: Yayy! New best EMA pseudo Dice: 0.2343\n",
      "2023-08-16 00:46:41.038715: \n",
      "2023-08-16 00:46:41.038896: Epoch 2\n",
      "2023-08-16 00:46:41.039005: Current learning rate: 0.00986\n",
      "2023-08-16 00:49:01.911167: train_loss -0.284\n",
      "2023-08-16 00:49:01.913656: val_loss -0.185\n",
      "2023-08-16 00:49:01.913773: Pseudo dice [0.1199]\n",
      "2023-08-16 00:49:01.913861: Epoch time: 140.87 s\n",
      "2023-08-16 00:49:04.724589: \n",
      "2023-08-16 00:49:04.724996: Epoch 3\n",
      "2023-08-16 00:49:04.725444: Current learning rate: 0.00978\n",
      "2023-08-16 00:51:24.375781: train_loss -0.3483\n",
      "2023-08-16 00:51:24.388015: val_loss -0.2587\n",
      "2023-08-16 00:51:24.388156: Pseudo dice [0.3165]\n",
      "2023-08-16 00:51:24.388247: Epoch time: 139.65 s\n",
      "2023-08-16 00:51:27.140481: \n",
      "2023-08-16 00:51:27.140645: Epoch 4\n",
      "2023-08-16 00:51:27.140761: Current learning rate: 0.00971\n",
      "2023-08-16 00:53:38.961048: train_loss -0.3566\n",
      "2023-08-16 00:53:38.964133: val_loss -0.282\n",
      "2023-08-16 00:53:38.964319: Pseudo dice [0.3819]\n",
      "2023-08-16 00:53:38.964424: Epoch time: 131.82 s\n",
      "2023-08-16 00:53:38.964490: Yayy! New best EMA pseudo Dice: 0.2472\n",
      "2023-08-16 00:53:42.354900: \n",
      "2023-08-16 00:53:42.355175: Epoch 5\n",
      "2023-08-16 00:53:42.355282: Current learning rate: 0.00964\n",
      "2023-08-16 00:55:56.014656: train_loss -0.3043\n",
      "2023-08-16 00:55:56.018751: val_loss -0.3477\n",
      "2023-08-16 00:55:56.018874: Pseudo dice [0.364]\n",
      "2023-08-16 00:55:56.019038: Epoch time: 133.66 s\n",
      "2023-08-16 00:55:56.019147: Yayy! New best EMA pseudo Dice: 0.2589\n",
      "2023-08-16 00:56:00.185400: \n",
      "2023-08-16 00:56:00.185847: Epoch 6\n",
      "2023-08-16 00:56:00.186315: Current learning rate: 0.00957\n",
      "2023-08-16 00:58:17.628208: train_loss -0.3714\n",
      "2023-08-16 00:58:17.630882: val_loss -0.3383\n",
      "2023-08-16 00:58:17.631022: Pseudo dice [0.4335]\n",
      "2023-08-16 00:58:17.631127: Epoch time: 137.44 s\n",
      "2023-08-16 00:58:17.631200: Yayy! New best EMA pseudo Dice: 0.2764\n",
      "2023-08-16 00:58:21.285253: \n",
      "2023-08-16 00:58:21.285530: Epoch 7\n",
      "2023-08-16 00:58:21.285678: Current learning rate: 0.00949\n",
      "2023-08-16 01:00:42.929292: train_loss -0.3821\n",
      "2023-08-16 01:00:42.933493: val_loss -0.2626\n",
      "2023-08-16 01:00:42.933630: Pseudo dice [0.2925]\n",
      "2023-08-16 01:00:42.933720: Epoch time: 141.65 s\n",
      "2023-08-16 01:00:42.933787: Yayy! New best EMA pseudo Dice: 0.278\n",
      "2023-08-16 01:00:46.674020: \n",
      "2023-08-16 01:00:46.674338: Epoch 8\n",
      "2023-08-16 01:00:46.674461: Current learning rate: 0.00942\n",
      "2023-08-16 01:03:01.099343: train_loss -0.3751\n",
      "2023-08-16 01:03:01.120254: val_loss -0.3032\n",
      "2023-08-16 01:03:01.120421: Pseudo dice [0.2973]\n",
      "2023-08-16 01:03:01.120527: Epoch time: 134.43 s\n",
      "2023-08-16 01:03:01.120620: Yayy! New best EMA pseudo Dice: 0.2799\n",
      "2023-08-16 01:03:04.867991: \n",
      "2023-08-16 01:03:04.868310: Epoch 9\n",
      "2023-08-16 01:03:04.868540: Current learning rate: 0.00935\n",
      "2023-08-16 01:05:22.140356: train_loss -0.3936\n",
      "2023-08-16 01:05:22.162297: val_loss -0.3269\n",
      "2023-08-16 01:05:22.162508: Pseudo dice [0.33]\n",
      "2023-08-16 01:05:22.162602: Epoch time: 137.27 s\n",
      "2023-08-16 01:05:22.162713: Yayy! New best EMA pseudo Dice: 0.2849\n",
      "2023-08-16 01:05:25.814016: \n",
      "2023-08-16 01:05:25.814168: Epoch 10\n",
      "2023-08-16 01:05:25.814268: Current learning rate: 0.00928\n",
      "2023-08-16 01:07:39.480734: train_loss -0.4053\n",
      "2023-08-16 01:07:39.485182: val_loss -0.284\n",
      "2023-08-16 01:07:39.485306: Pseudo dice [0.2021]\n",
      "2023-08-16 01:07:39.485400: Epoch time: 133.67 s\n",
      "2023-08-16 01:07:43.183633: \n",
      "2023-08-16 01:07:43.183955: Epoch 11\n",
      "2023-08-16 01:07:43.184092: Current learning rate: 0.0092\n",
      "2023-08-16 01:09:53.068113: train_loss -0.4096\n",
      "2023-08-16 01:09:53.069052: val_loss -0.2957\n",
      "2023-08-16 01:09:53.069159: Pseudo dice [0.3203]\n",
      "2023-08-16 01:09:53.069250: Epoch time: 129.89 s\n",
      "2023-08-16 01:09:56.739984: \n",
      "2023-08-16 01:09:56.740287: Epoch 12\n",
      "2023-08-16 01:09:56.740452: Current learning rate: 0.00913\n",
      "2023-08-16 01:12:28.784916: train_loss -0.4263\n",
      "2023-08-16 01:12:28.787105: val_loss -0.4073\n",
      "2023-08-16 01:12:28.787220: Pseudo dice [0.4508]\n",
      "2023-08-16 01:12:28.787307: Epoch time: 152.05 s\n",
      "2023-08-16 01:12:28.787369: Yayy! New best EMA pseudo Dice: 0.298\n",
      "2023-08-16 01:12:32.008631: \n",
      "2023-08-16 01:12:32.008914: Epoch 13\n",
      "2023-08-16 01:12:32.009041: Current learning rate: 0.00906\n",
      "2023-08-16 01:14:46.672310: train_loss -0.4292\n",
      "2023-08-16 01:14:46.680047: val_loss -0.4294\n",
      "2023-08-16 01:14:46.680203: Pseudo dice [0.455]\n",
      "2023-08-16 01:14:46.680283: Epoch time: 134.67 s\n",
      "2023-08-16 01:14:46.680347: Yayy! New best EMA pseudo Dice: 0.3137\n",
      "2023-08-16 01:14:50.934363: \n",
      "2023-08-16 01:14:50.934539: Epoch 14\n",
      "2023-08-16 01:14:50.934656: Current learning rate: 0.00899\n",
      "2023-08-16 01:17:07.192975: train_loss -0.4206\n",
      "2023-08-16 01:17:07.194298: val_loss -0.4006\n",
      "2023-08-16 01:17:07.194472: Pseudo dice [0.5645]\n",
      "2023-08-16 01:17:07.194766: Epoch time: 136.26 s\n",
      "2023-08-16 01:17:07.195275: Yayy! New best EMA pseudo Dice: 0.3388\n",
      "2023-08-16 01:17:11.175503: \n",
      "2023-08-16 01:17:11.175945: Epoch 15\n",
      "2023-08-16 01:17:11.176063: Current learning rate: 0.00891\n",
      "2023-08-16 01:19:34.562592: train_loss -0.432\n",
      "2023-08-16 01:19:34.579380: val_loss -0.2948\n",
      "2023-08-16 01:19:34.579682: Pseudo dice [0.3395]\n",
      "2023-08-16 01:19:34.580149: Epoch time: 143.39 s\n",
      "2023-08-16 01:19:34.580331: Yayy! New best EMA pseudo Dice: 0.3388\n",
      "2023-08-16 01:19:38.150862: \n",
      "2023-08-16 01:19:38.151004: Epoch 16\n",
      "2023-08-16 01:19:38.151156: Current learning rate: 0.00884\n",
      "2023-08-16 01:21:54.781660: train_loss -0.4637\n",
      "2023-08-16 01:21:54.792034: val_loss -0.3625\n",
      "2023-08-16 01:21:54.792194: Pseudo dice [0.3538]\n",
      "2023-08-16 01:21:54.792277: Epoch time: 136.63 s\n",
      "2023-08-16 01:21:54.792339: Yayy! New best EMA pseudo Dice: 0.3403\n",
      "2023-08-16 01:21:58.459134: \n",
      "2023-08-16 01:21:58.459558: Epoch 17\n",
      "2023-08-16 01:21:58.459783: Current learning rate: 0.00877\n",
      "2023-08-16 01:24:10.485939: train_loss -0.4347\n",
      "2023-08-16 01:24:10.502101: val_loss -0.401\n",
      "2023-08-16 01:24:10.502327: Pseudo dice [0.4625]\n",
      "2023-08-16 01:24:10.502519: Epoch time: 132.03 s\n",
      "2023-08-16 01:24:10.502682: Yayy! New best EMA pseudo Dice: 0.3526\n",
      "2023-08-16 01:24:14.110368: \n",
      "2023-08-16 01:24:14.110924: Epoch 18\n",
      "2023-08-16 01:24:14.111250: Current learning rate: 0.00869\n",
      "2023-08-16 01:26:28.893956: train_loss -0.4472\n",
      "2023-08-16 01:26:28.894748: val_loss -0.4103\n",
      "2023-08-16 01:26:28.894853: Pseudo dice [0.4715]\n",
      "2023-08-16 01:26:28.894936: Epoch time: 134.78 s\n",
      "2023-08-16 01:26:28.894998: Yayy! New best EMA pseudo Dice: 0.3645\n",
      "2023-08-16 01:26:31.896169: \n",
      "2023-08-16 01:26:31.896290: Epoch 19\n",
      "2023-08-16 01:26:31.896414: Current learning rate: 0.00862\n",
      "2023-08-16 01:28:50.922292: train_loss -0.3854\n",
      "2023-08-16 01:28:50.923817: val_loss -0.3296\n",
      "2023-08-16 01:28:50.923997: Pseudo dice [0.477]\n",
      "2023-08-16 01:28:50.924131: Epoch time: 139.03 s\n",
      "2023-08-16 01:28:50.924202: Yayy! New best EMA pseudo Dice: 0.3757\n",
      "2023-08-16 01:28:55.738572: \n",
      "2023-08-16 01:28:55.738771: Epoch 20\n",
      "2023-08-16 01:28:55.738917: Current learning rate: 0.00855\n",
      "2023-08-16 01:31:14.654941: train_loss -0.4368\n",
      "2023-08-16 01:31:14.657767: val_loss -0.4071\n",
      "2023-08-16 01:31:14.657881: Pseudo dice [0.4137]\n",
      "2023-08-16 01:31:14.657969: Epoch time: 138.92 s\n",
      "2023-08-16 01:31:14.658031: Yayy! New best EMA pseudo Dice: 0.3795\n",
      "2023-08-16 01:31:17.964957: \n",
      "2023-08-16 01:31:17.965145: Epoch 21\n",
      "2023-08-16 01:31:17.965277: Current learning rate: 0.00847\n",
      "2023-08-16 01:33:43.537160: train_loss -0.422\n",
      "2023-08-16 01:33:43.543152: val_loss -0.3472\n",
      "2023-08-16 01:33:43.543428: Pseudo dice [0.3672]\n",
      "2023-08-16 01:33:43.543525: Epoch time: 145.57 s\n",
      "2023-08-16 01:33:45.986013: \n",
      "2023-08-16 01:33:45.986399: Epoch 22\n",
      "2023-08-16 01:33:45.986525: Current learning rate: 0.0084\n",
      "2023-08-16 01:36:09.378354: train_loss -0.4596\n",
      "2023-08-16 01:36:09.393175: val_loss -0.3674\n",
      "2023-08-16 01:36:09.393315: Pseudo dice [0.4577]\n",
      "2023-08-16 01:36:09.393413: Epoch time: 143.39 s\n",
      "2023-08-16 01:36:09.393483: Yayy! New best EMA pseudo Dice: 0.3862\n",
      "2023-08-16 01:36:13.008553: \n",
      "2023-08-16 01:36:13.008874: Epoch 23\n",
      "2023-08-16 01:36:13.009086: Current learning rate: 0.00833\n",
      "2023-08-16 01:38:35.165315: train_loss -0.4686\n",
      "2023-08-16 01:38:35.165943: val_loss -0.411\n",
      "2023-08-16 01:38:35.166086: Pseudo dice [0.5126]\n",
      "2023-08-16 01:38:35.166168: Epoch time: 142.16 s\n",
      "2023-08-16 01:38:35.166227: Yayy! New best EMA pseudo Dice: 0.3989\n",
      "2023-08-16 01:38:38.452742: \n",
      "2023-08-16 01:38:38.452914: Epoch 24\n",
      "2023-08-16 01:38:38.453030: Current learning rate: 0.00825\n",
      "2023-08-16 01:41:05.729587: train_loss -0.4961\n",
      "2023-08-16 01:41:05.738499: val_loss -0.366\n",
      "2023-08-16 01:41:05.738772: Pseudo dice [0.4565]\n",
      "2023-08-16 01:41:05.738880: Epoch time: 147.28 s\n",
      "2023-08-16 01:41:06.432662: Yayy! New best EMA pseudo Dice: 0.4046\n",
      "2023-08-16 01:41:11.147465: \n",
      "2023-08-16 01:41:11.147635: Epoch 25\n",
      "2023-08-16 01:41:11.147740: Current learning rate: 0.00818\n",
      "2023-08-16 01:43:26.694377: train_loss -0.4707\n",
      "2023-08-16 01:43:26.695020: val_loss -0.4397\n",
      "2023-08-16 01:43:26.695116: Pseudo dice [0.4713]\n",
      "2023-08-16 01:43:26.695447: Epoch time: 135.55 s\n",
      "2023-08-16 01:43:26.695520: Yayy! New best EMA pseudo Dice: 0.4113\n",
      "2023-08-16 01:43:31.255730: \n",
      "2023-08-16 01:43:31.255934: Epoch 26\n",
      "2023-08-16 01:43:31.256052: Current learning rate: 0.00811\n",
      "2023-08-16 01:46:04.451206: train_loss -0.5297\n",
      "2023-08-16 01:46:04.456577: val_loss -0.538\n",
      "2023-08-16 01:46:04.456743: Pseudo dice [0.625]\n",
      "2023-08-16 01:46:04.456832: Epoch time: 153.2 s\n",
      "2023-08-16 01:46:04.456902: Yayy! New best EMA pseudo Dice: 0.4327\n",
      "2023-08-16 01:46:07.406388: \n",
      "2023-08-16 01:46:07.406509: Epoch 27\n",
      "2023-08-16 01:46:07.406646: Current learning rate: 0.00803\n",
      "2023-08-16 01:48:34.711096: train_loss -0.467\n",
      "2023-08-16 01:48:34.712272: val_loss -0.4723\n",
      "2023-08-16 01:48:34.712482: Pseudo dice [0.5676]\n",
      "2023-08-16 01:48:34.712604: Epoch time: 147.31 s\n",
      "2023-08-16 01:48:34.712673: Yayy! New best EMA pseudo Dice: 0.4461\n",
      "2023-08-16 01:48:38.609719: \n",
      "2023-08-16 01:48:38.610348: Epoch 28\n",
      "2023-08-16 01:48:38.610692: Current learning rate: 0.00796\n",
      "2023-08-16 01:51:08.193240: train_loss -0.5147\n",
      "2023-08-16 01:51:08.208024: val_loss -0.3597\n",
      "2023-08-16 01:51:08.208156: Pseudo dice [0.443]\n",
      "2023-08-16 01:51:08.208247: Epoch time: 149.58 s\n",
      "2023-08-16 01:51:11.342644: \n",
      "2023-08-16 01:51:11.342855: Epoch 29\n",
      "2023-08-16 01:51:11.343037: Current learning rate: 0.00789\n",
      "2023-08-16 01:53:38.757608: train_loss -0.5404\n",
      "2023-08-16 01:53:38.761997: val_loss -0.515\n",
      "2023-08-16 01:53:38.762186: Pseudo dice [0.5813]\n",
      "2023-08-16 01:53:38.762353: Epoch time: 147.42 s\n",
      "2023-08-16 01:53:38.762462: Yayy! New best EMA pseudo Dice: 0.4594\n",
      "2023-08-16 01:53:42.019854: \n",
      "2023-08-16 01:53:42.020183: Epoch 30\n",
      "2023-08-16 01:53:42.020410: Current learning rate: 0.00781\n",
      "2023-08-16 01:56:02.740649: train_loss -0.5056\n",
      "2023-08-16 01:56:02.741785: val_loss -0.4622\n",
      "2023-08-16 01:56:02.741889: Pseudo dice [0.4932]\n",
      "2023-08-16 01:56:02.741967: Epoch time: 140.72 s\n",
      "2023-08-16 01:56:02.742026: Yayy! New best EMA pseudo Dice: 0.4628\n",
      "2023-08-16 01:56:06.361737: \n",
      "2023-08-16 01:56:06.361907: Epoch 31\n",
      "2023-08-16 01:56:06.362030: Current learning rate: 0.00774\n",
      "2023-08-16 01:58:27.675982: train_loss -0.4965\n",
      "2023-08-16 01:58:27.677684: val_loss -0.4095\n",
      "2023-08-16 01:58:27.677789: Pseudo dice [0.3858]\n",
      "2023-08-16 01:58:27.677938: Epoch time: 141.32 s\n",
      "2023-08-16 01:58:29.653258: \n",
      "2023-08-16 01:58:29.653407: Epoch 32\n",
      "2023-08-16 01:58:29.653548: Current learning rate: 0.00766\n",
      "2023-08-16 02:01:00.148163: train_loss -0.4916\n",
      "2023-08-16 02:01:00.160052: val_loss -0.4383\n",
      "2023-08-16 02:01:00.160207: Pseudo dice [0.483]\n",
      "2023-08-16 02:01:00.160301: Epoch time: 150.5 s\n",
      "2023-08-16 02:01:03.956986: \n",
      "2023-08-16 02:01:03.957171: Epoch 33\n",
      "2023-08-16 02:01:03.957286: Current learning rate: 0.00759\n",
      "2023-08-16 02:03:39.321324: train_loss -0.5071\n",
      "2023-08-16 02:03:39.336034: val_loss -0.4041\n",
      "2023-08-16 02:03:39.336181: Pseudo dice [0.4907]\n",
      "2023-08-16 02:03:39.336272: Epoch time: 155.37 s\n",
      "2023-08-16 02:03:42.086452: \n",
      "2023-08-16 02:03:42.086606: Epoch 34\n",
      "2023-08-16 02:03:42.086707: Current learning rate: 0.00751\n",
      "2023-08-16 02:06:08.044878: train_loss -0.4623\n",
      "2023-08-16 02:06:08.046429: val_loss -0.416\n",
      "2023-08-16 02:06:08.046558: Pseudo dice [0.5348]\n",
      "2023-08-16 02:06:08.046653: Epoch time: 145.96 s\n",
      "2023-08-16 02:06:08.046721: Yayy! New best EMA pseudo Dice: 0.4685\n",
      "2023-08-16 02:06:11.224290: \n",
      "2023-08-16 02:06:11.224451: Epoch 35\n",
      "2023-08-16 02:06:11.224581: Current learning rate: 0.00744\n",
      "2023-08-16 02:08:54.231917: train_loss -0.4882\n",
      "2023-08-16 02:08:54.245119: val_loss -0.4102\n",
      "2023-08-16 02:08:54.245240: Pseudo dice [0.4701]\n",
      "2023-08-16 02:08:54.245331: Epoch time: 163.01 s\n",
      "2023-08-16 02:08:54.245394: Yayy! New best EMA pseudo Dice: 0.4687\n",
      "2023-08-16 02:08:58.219202: \n",
      "2023-08-16 02:08:58.219332: Epoch 36\n",
      "2023-08-16 02:08:58.219441: Current learning rate: 0.00737\n",
      "2023-08-16 02:11:39.033201: train_loss -0.5107\n",
      "2023-08-16 02:11:39.034292: val_loss -0.4437\n",
      "2023-08-16 02:11:39.034464: Pseudo dice [0.5897]\n",
      "2023-08-16 02:11:39.034570: Epoch time: 160.82 s\n",
      "2023-08-16 02:11:39.034638: Yayy! New best EMA pseudo Dice: 0.4808\n",
      "2023-08-16 02:11:42.245304: \n",
      "2023-08-16 02:11:42.245716: Epoch 37\n",
      "2023-08-16 02:11:42.245885: Current learning rate: 0.00729\n",
      "2023-08-16 02:15:26.945389: train_loss -0.5087\n",
      "2023-08-16 02:15:26.954247: val_loss -0.4515\n",
      "2023-08-16 02:15:26.954512: Pseudo dice [0.477]\n",
      "2023-08-16 02:15:26.954607: Epoch time: 224.7 s\n",
      "2023-08-16 02:15:31.190742: \n",
      "2023-08-16 02:15:31.190927: Epoch 38\n",
      "2023-08-16 02:15:31.191066: Current learning rate: 0.00722\n",
      "2023-08-16 02:18:10.028778: train_loss -0.5026\n",
      "2023-08-16 02:18:10.029667: val_loss -0.4333\n",
      "2023-08-16 02:18:10.029768: Pseudo dice [0.5863]\n",
      "2023-08-16 02:18:10.029853: Epoch time: 158.84 s\n",
      "2023-08-16 02:18:10.029979: Yayy! New best EMA pseudo Dice: 0.491\n",
      "2023-08-16 02:18:13.297369: \n",
      "2023-08-16 02:18:13.297836: Epoch 39\n",
      "2023-08-16 02:18:13.297991: Current learning rate: 0.00714\n",
      "2023-08-16 02:20:44.249965: train_loss -0.5094\n",
      "2023-08-16 02:20:44.260027: val_loss -0.435\n",
      "2023-08-16 02:20:44.260169: Pseudo dice [0.5148]\n",
      "2023-08-16 02:20:44.260266: Epoch time: 150.96 s\n",
      "2023-08-16 02:20:44.260336: Yayy! New best EMA pseudo Dice: 0.4934\n",
      "2023-08-16 02:20:48.934159: \n",
      "2023-08-16 02:20:48.934492: Epoch 40\n",
      "2023-08-16 02:20:48.934723: Current learning rate: 0.00707\n",
      "2023-08-16 02:23:22.683522: train_loss -0.506\n",
      "2023-08-16 02:23:22.685179: val_loss -0.3138\n",
      "2023-08-16 02:23:22.685422: Pseudo dice [0.4712]\n",
      "2023-08-16 02:23:22.685543: Epoch time: 153.75 s\n",
      "2023-08-16 02:23:25.978595: \n",
      "2023-08-16 02:23:25.978775: Epoch 41\n",
      "2023-08-16 02:23:25.978894: Current learning rate: 0.00699\n",
      "2023-08-16 02:26:04.723812: train_loss -0.4675\n",
      "2023-08-16 02:26:04.725028: val_loss -0.3626\n",
      "2023-08-16 02:26:04.725152: Pseudo dice [0.2914]\n",
      "2023-08-16 02:26:04.725245: Epoch time: 158.75 s\n",
      "2023-08-16 02:26:07.722687: \n",
      "2023-08-16 02:26:07.723121: Epoch 42\n",
      "2023-08-16 02:26:07.723241: Current learning rate: 0.00692\n",
      "2023-08-16 02:28:39.131361: train_loss -0.5136\n",
      "2023-08-16 02:28:39.144043: val_loss -0.4916\n",
      "2023-08-16 02:28:39.144191: Pseudo dice [0.5233]\n",
      "2023-08-16 02:28:39.144284: Epoch time: 151.41 s\n",
      "2023-08-16 02:28:41.374303: \n",
      "2023-08-16 02:28:41.374442: Epoch 43\n",
      "2023-08-16 02:28:41.374561: Current learning rate: 0.00684\n",
      "2023-08-16 02:31:06.832876: train_loss -0.4615\n",
      "2023-08-16 02:31:06.836124: val_loss -0.3565\n",
      "2023-08-16 02:31:06.836413: Pseudo dice [0.5168]\n",
      "2023-08-16 02:31:06.836573: Epoch time: 145.46 s\n",
      "2023-08-16 02:31:09.436217: \n",
      "2023-08-16 02:31:09.436430: Epoch 44\n",
      "2023-08-16 02:31:09.436586: Current learning rate: 0.00677\n",
      "2023-08-16 02:33:35.826172: train_loss -0.5107\n",
      "2023-08-16 02:33:35.826528: val_loss -0.4078\n",
      "2023-08-16 02:33:35.826695: Pseudo dice [0.5412]\n",
      "2023-08-16 02:33:35.826836: Epoch time: 146.39 s\n",
      "2023-08-16 02:33:37.667446: \n",
      "2023-08-16 02:33:37.667588: Epoch 45\n",
      "2023-08-16 02:33:37.667702: Current learning rate: 0.00669\n",
      "2023-08-16 02:36:03.480386: train_loss -0.4991\n",
      "2023-08-16 02:36:03.481608: val_loss -0.4393\n",
      "2023-08-16 02:36:03.481720: Pseudo dice [0.4468]\n",
      "2023-08-16 02:36:03.481817: Epoch time: 145.81 s\n",
      "2023-08-16 02:36:06.408278: \n",
      "2023-08-16 02:36:06.408507: Epoch 46\n",
      "2023-08-16 02:36:06.408686: Current learning rate: 0.00662\n",
      "2023-08-16 02:38:27.716028: train_loss -0.5018\n",
      "2023-08-16 02:38:27.717100: val_loss -0.4161\n",
      "2023-08-16 02:38:27.717217: Pseudo dice [0.4775]\n",
      "2023-08-16 02:38:27.717303: Epoch time: 141.31 s\n",
      "2023-08-16 02:38:30.465346: \n",
      "2023-08-16 02:38:30.465493: Epoch 47\n",
      "2023-08-16 02:38:30.465607: Current learning rate: 0.00654\n",
      "2023-08-16 02:40:53.979235: train_loss -0.5066\n",
      "2023-08-16 02:40:53.980394: val_loss -0.3853\n",
      "2023-08-16 02:40:53.980511: Pseudo dice [0.4396]\n",
      "2023-08-16 02:40:53.980600: Epoch time: 143.52 s\n",
      "2023-08-16 02:40:55.914559: \n",
      "2023-08-16 02:40:55.914697: Epoch 48\n",
      "2023-08-16 02:40:55.914804: Current learning rate: 0.00647\n",
      "2023-08-16 02:43:23.961726: train_loss -0.4898\n",
      "2023-08-16 02:43:23.968060: val_loss -0.4102\n",
      "2023-08-16 02:43:23.968225: Pseudo dice [0.5525]\n",
      "2023-08-16 02:43:23.968322: Epoch time: 148.05 s\n",
      "2023-08-16 02:43:25.909504: \n",
      "2023-08-16 02:43:25.909697: Epoch 49\n",
      "2023-08-16 02:43:25.909842: Current learning rate: 0.00639\n",
      "2023-08-16 02:45:43.758348: train_loss -0.4686\n",
      "2023-08-16 02:45:43.761143: val_loss -0.4825\n",
      "2023-08-16 02:45:43.761323: Pseudo dice [0.5389]\n",
      "2023-08-16 02:45:43.761508: Epoch time: 137.85 s\n",
      "2023-08-16 02:45:47.022027: \n",
      "2023-08-16 02:45:47.022454: Epoch 50\n",
      "2023-08-16 02:45:47.022576: Current learning rate: 0.00631\n",
      "2023-08-16 02:48:11.510586: train_loss -0.5144\n",
      "2023-08-16 02:48:11.511617: val_loss -0.4393\n",
      "2023-08-16 02:48:11.511780: Pseudo dice [0.4832]\n",
      "2023-08-16 02:48:11.511938: Epoch time: 144.49 s\n",
      "2023-08-16 02:48:13.591088: \n",
      "2023-08-16 02:48:13.591240: Epoch 51\n",
      "2023-08-16 02:48:13.591362: Current learning rate: 0.00624\n",
      "2023-08-16 02:50:38.623919: train_loss -0.5039\n",
      "2023-08-16 02:50:38.625249: val_loss -0.4398\n",
      "2023-08-16 02:50:38.625368: Pseudo dice [0.5973]\n",
      "2023-08-16 02:50:38.625543: Epoch time: 145.03 s\n",
      "2023-08-16 02:50:38.625672: Yayy! New best EMA pseudo Dice: 0.5006\n",
      "2023-08-16 02:50:42.819645: \n",
      "2023-08-16 02:50:42.819770: Epoch 52\n",
      "2023-08-16 02:50:42.819889: Current learning rate: 0.00616\n",
      "2023-08-16 02:53:02.522864: train_loss -0.588\n",
      "2023-08-16 02:53:02.525239: val_loss -0.4308\n",
      "2023-08-16 02:53:02.525330: Pseudo dice [0.5805]\n",
      "2023-08-16 02:53:02.525418: Epoch time: 139.7 s\n",
      "2023-08-16 02:53:02.525479: Yayy! New best EMA pseudo Dice: 0.5086\n",
      "2023-08-16 02:53:05.913877: \n",
      "2023-08-16 02:53:05.914255: Epoch 53\n",
      "2023-08-16 02:53:05.914384: Current learning rate: 0.00609\n",
      "2023-08-16 02:55:30.078880: train_loss -0.5814\n",
      "2023-08-16 02:55:30.081441: val_loss -0.4151\n",
      "2023-08-16 02:55:30.081568: Pseudo dice [0.5718]\n",
      "2023-08-16 02:55:30.081654: Epoch time: 144.17 s\n",
      "2023-08-16 02:55:30.081717: Yayy! New best EMA pseudo Dice: 0.5149\n",
      "2023-08-16 02:55:33.392320: \n",
      "2023-08-16 02:55:33.392626: Epoch 54\n",
      "2023-08-16 02:55:33.392771: Current learning rate: 0.00601\n",
      "2023-08-16 02:57:50.580338: train_loss -0.4966\n",
      "2023-08-16 02:57:50.592045: val_loss -0.5099\n",
      "2023-08-16 02:57:50.592204: Pseudo dice [0.6136]\n",
      "2023-08-16 02:57:50.592299: Epoch time: 137.19 s\n",
      "2023-08-16 02:57:50.592366: Yayy! New best EMA pseudo Dice: 0.5248\n",
      "2023-08-16 02:57:54.403482: \n",
      "2023-08-16 02:57:54.403644: Epoch 55\n",
      "2023-08-16 02:57:54.403751: Current learning rate: 0.00593\n",
      "2023-08-16 03:00:18.613077: train_loss -0.5427\n",
      "2023-08-16 03:00:18.624024: val_loss -0.3567\n",
      "2023-08-16 03:00:18.624179: Pseudo dice [0.5214]\n",
      "2023-08-16 03:00:18.624265: Epoch time: 144.21 s\n",
      "2023-08-16 03:00:21.568757: \n",
      "2023-08-16 03:00:21.569101: Epoch 56\n",
      "2023-08-16 03:00:21.569257: Current learning rate: 0.00586\n",
      "2023-08-16 03:02:47.985367: train_loss -0.5564\n",
      "2023-08-16 03:02:47.994383: val_loss -0.4368\n",
      "2023-08-16 03:02:47.994505: Pseudo dice [0.5386]\n",
      "2023-08-16 03:02:47.994591: Epoch time: 146.42 s\n",
      "2023-08-16 03:02:47.994655: Yayy! New best EMA pseudo Dice: 0.5259\n",
      "2023-08-16 03:02:51.749990: \n",
      "2023-08-16 03:02:51.750126: Epoch 57\n",
      "2023-08-16 03:02:51.750233: Current learning rate: 0.00578\n",
      "2023-08-16 03:05:36.606976: train_loss -0.6027\n",
      "2023-08-16 03:05:36.609157: val_loss -0.4027\n",
      "2023-08-16 03:05:36.609253: Pseudo dice [0.5753]\n",
      "2023-08-16 03:05:36.609337: Epoch time: 164.86 s\n",
      "2023-08-16 03:05:36.609401: Yayy! New best EMA pseudo Dice: 0.5308\n",
      "2023-08-16 03:05:39.627452: \n",
      "2023-08-16 03:05:39.627581: Epoch 58\n",
      "2023-08-16 03:05:39.627695: Current learning rate: 0.0057\n",
      "2023-08-16 03:08:12.596670: train_loss -0.5501\n",
      "2023-08-16 03:08:12.604220: val_loss -0.4497\n",
      "2023-08-16 03:08:12.604368: Pseudo dice [0.5386]\n",
      "2023-08-16 03:08:12.604499: Epoch time: 152.97 s\n",
      "2023-08-16 03:08:12.604590: Yayy! New best EMA pseudo Dice: 0.5316\n",
      "2023-08-16 03:08:16.779158: \n",
      "2023-08-16 03:08:16.779382: Epoch 59\n",
      "2023-08-16 03:08:16.779616: Current learning rate: 0.00563\n",
      "2023-08-16 03:10:58.757635: train_loss -0.5355\n",
      "2023-08-16 03:10:58.780701: val_loss -0.4687\n",
      "2023-08-16 03:10:58.780808: Pseudo dice [0.5245]\n",
      "2023-08-16 03:10:58.780884: Epoch time: 161.98 s\n",
      "2023-08-16 03:11:01.602780: \n",
      "2023-08-16 03:11:01.602928: Epoch 60\n",
      "2023-08-16 03:11:01.603031: Current learning rate: 0.00555\n",
      "2023-08-16 03:14:15.205276: train_loss -0.5726\n",
      "2023-08-16 03:14:15.220061: val_loss -0.4467\n",
      "2023-08-16 03:14:15.220253: Pseudo dice [0.5888]\n",
      "2023-08-16 03:14:15.220360: Epoch time: 193.6 s\n",
      "2023-08-16 03:14:15.220433: Yayy! New best EMA pseudo Dice: 0.5367\n",
      "2023-08-16 03:14:20.813025: \n",
      "2023-08-16 03:14:20.813210: Epoch 61\n",
      "2023-08-16 03:14:20.813331: Current learning rate: 0.00547\n",
      "2023-08-16 03:21:22.292150: train_loss -0.5589\n",
      "2023-08-16 03:21:22.292834: val_loss -0.5116\n",
      "2023-08-16 03:21:22.292937: Pseudo dice [0.516]\n",
      "2023-08-16 03:21:22.293024: Epoch time: 421.48 s\n",
      "2023-08-16 03:21:25.983497: \n",
      "2023-08-16 03:21:25.983832: Epoch 62\n",
      "2023-08-16 03:21:25.984056: Current learning rate: 0.0054\n",
      "2023-08-16 03:23:53.464993: train_loss -0.5668\n",
      "2023-08-16 03:23:53.466321: val_loss -0.5112\n",
      "2023-08-16 03:23:53.466570: Pseudo dice [0.5494]\n",
      "2023-08-16 03:23:53.466664: Epoch time: 147.48 s\n",
      "2023-08-16 03:23:56.380391: \n",
      "2023-08-16 03:23:56.380555: Epoch 63\n",
      "2023-08-16 03:23:56.380685: Current learning rate: 0.00532\n",
      "2023-08-16 03:26:12.143745: train_loss -0.4662\n",
      "2023-08-16 03:26:12.144641: val_loss -0.3892\n",
      "2023-08-16 03:26:12.144722: Pseudo dice [0.4069]\n",
      "2023-08-16 03:26:12.144793: Epoch time: 135.77 s\n",
      "2023-08-16 03:26:14.062150: \n",
      "2023-08-16 03:26:14.062285: Epoch 64\n",
      "2023-08-16 03:26:14.062407: Current learning rate: 0.00524\n",
      "2023-08-16 03:28:41.744386: train_loss -0.4921\n",
      "2023-08-16 03:28:41.748507: val_loss -0.4185\n",
      "2023-08-16 03:28:41.748608: Pseudo dice [0.5065]\n",
      "2023-08-16 03:28:41.748690: Epoch time: 147.68 s\n",
      "2023-08-16 03:28:43.573600: \n",
      "2023-08-16 03:28:43.573895: Epoch 65\n",
      "2023-08-16 03:28:43.574081: Current learning rate: 0.00517\n",
      "2023-08-16 03:31:24.016088: train_loss -0.5426\n",
      "2023-08-16 03:31:24.018303: val_loss -0.4254\n",
      "2023-08-16 03:31:24.018402: Pseudo dice [0.5351]\n",
      "2023-08-16 03:31:24.018488: Epoch time: 160.44 s\n",
      "2023-08-16 03:31:26.275525: \n",
      "2023-08-16 03:31:26.275660: Epoch 66\n",
      "2023-08-16 03:31:26.275771: Current learning rate: 0.00509\n",
      "2023-08-16 03:34:15.101029: train_loss -0.5211\n",
      "2023-08-16 03:34:15.103061: val_loss -0.4073\n",
      "2023-08-16 03:34:15.103154: Pseudo dice [0.4247]\n",
      "2023-08-16 03:34:15.103237: Epoch time: 168.83 s\n",
      "2023-08-16 03:34:17.102072: \n",
      "2023-08-16 03:34:17.102406: Epoch 67\n",
      "2023-08-16 03:34:17.102630: Current learning rate: 0.00501\n",
      "2023-08-16 03:37:09.315652: train_loss -0.5377\n",
      "2023-08-16 03:37:09.317323: val_loss -0.4465\n",
      "2023-08-16 03:37:09.317533: Pseudo dice [0.5321]\n",
      "2023-08-16 03:37:09.317644: Epoch time: 172.21 s\n",
      "2023-08-16 03:37:11.277377: \n",
      "2023-08-16 03:37:11.277657: Epoch 68\n",
      "2023-08-16 03:37:11.277819: Current learning rate: 0.00493\n",
      "2023-08-16 03:39:33.380877: train_loss -0.5126\n",
      "2023-08-16 03:39:33.397845: val_loss -0.3978\n",
      "2023-08-16 03:39:33.398069: Pseudo dice [0.4943]\n",
      "2023-08-16 03:39:33.398168: Epoch time: 142.1 s\n",
      "2023-08-16 03:39:36.466629: \n",
      "2023-08-16 03:39:36.467131: Epoch 69\n",
      "2023-08-16 03:39:36.467364: Current learning rate: 0.00485\n",
      "2023-08-16 03:42:02.393796: train_loss -0.6019\n",
      "2023-08-16 03:42:02.394533: val_loss -0.4244\n",
      "2023-08-16 03:42:02.394687: Pseudo dice [0.4924]\n",
      "2023-08-16 03:42:02.394836: Epoch time: 145.93 s\n",
      "2023-08-16 03:42:04.592502: \n",
      "2023-08-16 03:42:04.592653: Epoch 70\n",
      "2023-08-16 03:42:04.592753: Current learning rate: 0.00478\n",
      "2023-08-16 03:44:26.429345: train_loss -0.5472\n",
      "2023-08-16 03:44:26.430717: val_loss -0.4058\n",
      "2023-08-16 03:44:26.430817: Pseudo dice [0.4863]\n",
      "2023-08-16 03:44:26.430920: Epoch time: 141.84 s\n",
      "2023-08-16 03:44:28.344169: \n",
      "2023-08-16 03:44:28.344351: Epoch 71\n",
      "2023-08-16 03:44:28.344460: Current learning rate: 0.0047\n",
      "2023-08-16 03:47:01.717040: train_loss -0.5565\n",
      "2023-08-16 03:47:01.718696: val_loss -0.3944\n",
      "2023-08-16 03:47:01.718796: Pseudo dice [0.4273]\n",
      "2023-08-16 03:47:01.718880: Epoch time: 153.37 s\n",
      "2023-08-16 03:47:03.624563: \n",
      "2023-08-16 03:47:03.624683: Epoch 72\n",
      "2023-08-16 03:47:03.624779: Current learning rate: 0.00462\n",
      "2023-08-16 03:49:29.357267: train_loss -0.5393\n",
      "2023-08-16 03:49:29.359409: val_loss -0.4229\n",
      "2023-08-16 03:49:29.359522: Pseudo dice [0.5106]\n",
      "2023-08-16 03:49:29.359629: Epoch time: 145.73 s\n",
      "2023-08-16 03:49:31.589272: \n",
      "2023-08-16 03:49:31.589572: Epoch 73\n",
      "2023-08-16 03:49:31.589787: Current learning rate: 0.00454\n",
      "2023-08-16 03:51:59.453149: train_loss -0.5497\n",
      "2023-08-16 03:51:59.455388: val_loss -0.4568\n",
      "2023-08-16 03:51:59.455501: Pseudo dice [0.5314]\n",
      "2023-08-16 03:51:59.455590: Epoch time: 147.87 s\n",
      "2023-08-16 03:52:01.675623: \n",
      "2023-08-16 03:52:01.675762: Epoch 74\n",
      "2023-08-16 03:52:01.675880: Current learning rate: 0.00446\n",
      "2023-08-16 03:54:33.611259: train_loss -0.549\n",
      "2023-08-16 03:54:33.618508: val_loss -0.448\n",
      "2023-08-16 03:54:33.618661: Pseudo dice [0.552]\n",
      "2023-08-16 03:54:33.618745: Epoch time: 151.94 s\n",
      "2023-08-16 03:54:37.087554: \n",
      "2023-08-16 03:54:37.087733: Epoch 75\n",
      "2023-08-16 03:54:37.087837: Current learning rate: 0.00438\n",
      "2023-08-16 03:57:04.474060: train_loss -0.5688\n",
      "2023-08-16 03:57:04.474977: val_loss -0.3351\n",
      "2023-08-16 03:57:04.475089: Pseudo dice [0.4276]\n",
      "2023-08-16 03:57:04.475196: Epoch time: 147.39 s\n",
      "2023-08-16 03:57:06.441574: \n",
      "2023-08-16 03:57:06.441810: Epoch 76\n",
      "2023-08-16 03:57:06.442300: Current learning rate: 0.0043\n",
      "2023-08-16 03:59:30.991328: train_loss -0.5212\n",
      "2023-08-16 03:59:30.993483: val_loss -0.4508\n",
      "2023-08-16 03:59:30.993583: Pseudo dice [0.5037]\n",
      "2023-08-16 03:59:30.993669: Epoch time: 144.55 s\n",
      "2023-08-16 03:59:32.978303: \n",
      "2023-08-16 03:59:32.978538: Epoch 77\n",
      "2023-08-16 03:59:32.978783: Current learning rate: 0.00423\n",
      "2023-08-16 04:01:52.699656: train_loss -0.59\n",
      "2023-08-16 04:01:52.703730: val_loss -0.4336\n",
      "2023-08-16 04:01:52.703831: Pseudo dice [0.473]\n",
      "2023-08-16 04:01:52.703949: Epoch time: 139.72 s\n",
      "2023-08-16 04:01:54.677560: \n",
      "2023-08-16 04:01:54.677684: Epoch 78\n",
      "2023-08-16 04:01:54.677788: Current learning rate: 0.00415\n",
      "2023-08-16 04:04:17.630339: train_loss -0.5597\n",
      "2023-08-16 04:04:17.638682: val_loss -0.457\n",
      "2023-08-16 04:04:17.638828: Pseudo dice [0.4944]\n",
      "2023-08-16 04:04:17.638908: Epoch time: 142.95 s\n",
      "2023-08-16 04:04:20.057381: \n",
      "2023-08-16 04:04:20.057540: Epoch 79\n",
      "2023-08-16 04:04:20.057669: Current learning rate: 0.00407\n",
      "2023-08-16 04:06:46.468429: train_loss -0.5655\n",
      "2023-08-16 04:06:46.471756: val_loss -0.4977\n",
      "2023-08-16 04:06:46.471883: Pseudo dice [0.5631]\n",
      "2023-08-16 04:06:46.471979: Epoch time: 146.41 s\n",
      "2023-08-16 04:06:48.605032: \n",
      "2023-08-16 04:06:48.605179: Epoch 80\n",
      "2023-08-16 04:06:48.605297: Current learning rate: 0.00399\n",
      "2023-08-16 04:09:17.044435: train_loss -0.568\n",
      "2023-08-16 04:09:17.046999: val_loss -0.4502\n",
      "2023-08-16 04:09:17.047168: Pseudo dice [0.5693]\n",
      "2023-08-16 04:09:17.047290: Epoch time: 148.44 s\n",
      "2023-08-16 04:09:19.075447: \n",
      "2023-08-16 04:09:19.075590: Epoch 81\n",
      "2023-08-16 04:09:19.075733: Current learning rate: 0.00391\n",
      "2023-08-16 04:11:38.937172: train_loss -0.5983\n",
      "2023-08-16 04:11:38.939099: val_loss -0.4424\n",
      "2023-08-16 04:11:38.939299: Pseudo dice [0.5227]\n",
      "2023-08-16 04:11:38.939466: Epoch time: 139.86 s\n",
      "2023-08-16 04:11:41.030765: \n",
      "2023-08-16 04:11:41.030901: Epoch 82\n",
      "2023-08-16 04:11:41.031026: Current learning rate: 0.00383\n",
      "2023-08-16 04:14:10.733783: train_loss -0.57\n",
      "2023-08-16 04:14:10.736536: val_loss -0.4611\n",
      "2023-08-16 04:14:10.736662: Pseudo dice [0.5311]\n",
      "2023-08-16 04:14:10.736760: Epoch time: 149.7 s\n",
      "2023-08-16 04:14:12.746306: \n",
      "2023-08-16 04:14:12.746601: Epoch 83\n",
      "2023-08-16 04:14:12.746817: Current learning rate: 0.00375\n",
      "2023-08-16 04:16:37.184053: train_loss -0.5744\n",
      "2023-08-16 04:16:37.185078: val_loss -0.4756\n",
      "2023-08-16 04:16:37.185183: Pseudo dice [0.4494]\n",
      "2023-08-16 04:16:37.185270: Epoch time: 144.44 s\n",
      "2023-08-16 04:16:39.094607: \n",
      "2023-08-16 04:16:39.094733: Epoch 84\n",
      "2023-08-16 04:16:39.094846: Current learning rate: 0.00367\n",
      "2023-08-16 04:19:10.467178: train_loss -0.5886\n",
      "2023-08-16 04:19:10.468667: val_loss -0.5107\n",
      "2023-08-16 04:19:10.468758: Pseudo dice [0.6444]\n",
      "2023-08-16 04:19:10.468843: Epoch time: 151.37 s\n",
      "2023-08-16 04:19:12.484762: \n",
      "2023-08-16 04:19:12.485017: Epoch 85\n",
      "2023-08-16 04:19:12.485339: Current learning rate: 0.00359\n",
      "2023-08-16 04:21:30.275767: train_loss -0.5489\n",
      "2023-08-16 04:21:30.277456: val_loss -0.4797\n",
      "2023-08-16 04:21:30.277647: Pseudo dice [0.5702]\n",
      "2023-08-16 04:21:30.277754: Epoch time: 137.79 s\n",
      "2023-08-16 04:21:32.810578: \n",
      "2023-08-16 04:21:32.810748: Epoch 86\n",
      "2023-08-16 04:21:32.810880: Current learning rate: 0.00351\n",
      "2023-08-16 04:23:47.989068: train_loss -0.5926\n",
      "2023-08-16 04:23:47.992229: val_loss -0.4992\n",
      "2023-08-16 04:23:47.992338: Pseudo dice [0.5005]\n",
      "2023-08-16 04:23:47.992421: Epoch time: 135.18 s\n",
      "2023-08-16 04:23:49.844923: \n",
      "2023-08-16 04:23:49.845073: Epoch 87\n",
      "2023-08-16 04:23:49.845178: Current learning rate: 0.00342\n",
      "2023-08-16 04:26:13.862614: train_loss -0.6005\n",
      "2023-08-16 04:26:13.865596: val_loss -0.4128\n",
      "2023-08-16 04:26:13.865950: Pseudo dice [0.5057]\n",
      "2023-08-16 04:26:13.866055: Epoch time: 144.02 s\n",
      "2023-08-16 04:26:15.868187: \n",
      "2023-08-16 04:26:15.868456: Epoch 88\n",
      "2023-08-16 04:26:15.868603: Current learning rate: 0.00334\n",
      "2023-08-16 04:28:44.100380: train_loss -0.5795\n",
      "2023-08-16 04:28:44.101825: val_loss -0.3739\n",
      "2023-08-16 04:28:44.101992: Pseudo dice [0.4927]\n",
      "2023-08-16 04:28:44.102159: Epoch time: 148.23 s\n",
      "2023-08-16 04:28:46.049104: \n",
      "2023-08-16 04:28:46.049465: Epoch 89\n",
      "2023-08-16 04:28:46.049690: Current learning rate: 0.00326\n",
      "2023-08-16 04:31:10.053620: train_loss -0.5595\n",
      "2023-08-16 04:31:10.055412: val_loss -0.5265\n",
      "2023-08-16 04:31:10.055524: Pseudo dice [0.6399]\n",
      "2023-08-16 04:31:10.055614: Epoch time: 144.01 s\n",
      "2023-08-16 04:31:12.089839: \n",
      "2023-08-16 04:31:12.089983: Epoch 90\n",
      "2023-08-16 04:31:12.090104: Current learning rate: 0.00318\n",
      "2023-08-16 04:33:29.000044: train_loss -0.5694\n",
      "2023-08-16 04:33:29.002283: val_loss -0.4871\n",
      "2023-08-16 04:33:29.002392: Pseudo dice [0.5881]\n",
      "2023-08-16 04:33:29.002465: Epoch time: 136.91 s\n",
      "2023-08-16 04:33:29.002523: Yayy! New best EMA pseudo Dice: 0.5367\n",
      "2023-08-16 04:33:32.226917: \n",
      "2023-08-16 04:33:32.227076: Epoch 91\n",
      "2023-08-16 04:33:32.227192: Current learning rate: 0.0031\n",
      "2023-08-16 04:35:56.882348: train_loss -0.5648\n",
      "2023-08-16 04:35:56.883824: val_loss -0.4843\n",
      "2023-08-16 04:35:56.883951: Pseudo dice [0.5262]\n",
      "2023-08-16 04:35:56.884047: Epoch time: 144.66 s\n",
      "2023-08-16 04:35:58.761001: \n",
      "2023-08-16 04:35:58.761159: Epoch 92\n",
      "2023-08-16 04:35:58.761259: Current learning rate: 0.00302\n",
      "2023-08-16 04:38:21.159658: train_loss -0.5681\n",
      "2023-08-16 04:38:21.180074: val_loss -0.4141\n",
      "2023-08-16 04:38:21.180539: Pseudo dice [0.5184]\n",
      "2023-08-16 04:38:21.181344: Epoch time: 142.4 s\n",
      "2023-08-16 04:38:23.643383: \n",
      "2023-08-16 04:38:23.643622: Epoch 93\n",
      "2023-08-16 04:38:23.643825: Current learning rate: 0.00293\n",
      "2023-08-16 04:40:51.177190: train_loss -0.6057\n",
      "2023-08-16 04:40:51.178426: val_loss -0.4557\n",
      "2023-08-16 04:40:51.178508: Pseudo dice [0.5387]\n",
      "2023-08-16 04:40:51.178589: Epoch time: 147.54 s\n",
      "2023-08-16 04:40:53.122742: \n",
      "2023-08-16 04:40:53.122999: Epoch 94\n",
      "2023-08-16 04:40:53.123151: Current learning rate: 0.00285\n",
      "2023-08-16 04:43:12.348921: train_loss -0.617\n",
      "2023-08-16 04:43:12.350118: val_loss -0.532\n",
      "2023-08-16 04:43:12.350229: Pseudo dice [0.6609]\n",
      "2023-08-16 04:43:12.350311: Epoch time: 139.23 s\n",
      "2023-08-16 04:43:12.350374: Yayy! New best EMA pseudo Dice: 0.547\n",
      "2023-08-16 04:43:15.799028: \n",
      "2023-08-16 04:43:15.799160: Epoch 95\n",
      "2023-08-16 04:43:15.799279: Current learning rate: 0.00277\n",
      "2023-08-16 04:45:39.660867: train_loss -0.5998\n",
      "2023-08-16 04:45:39.663416: val_loss -0.5224\n",
      "2023-08-16 04:45:39.663517: Pseudo dice [0.6937]\n",
      "2023-08-16 04:45:39.663601: Epoch time: 143.86 s\n",
      "2023-08-16 04:45:39.663679: Yayy! New best EMA pseudo Dice: 0.5617\n",
      "2023-08-16 04:45:43.132783: \n",
      "2023-08-16 04:45:43.132931: Epoch 96\n",
      "2023-08-16 04:45:43.133035: Current learning rate: 0.00268\n",
      "2023-08-16 04:48:07.111934: train_loss -0.5851\n",
      "2023-08-16 04:48:07.128012: val_loss -0.4741\n",
      "2023-08-16 04:48:07.128187: Pseudo dice [0.5165]\n",
      "2023-08-16 04:48:07.128317: Epoch time: 143.98 s\n",
      "2023-08-16 04:48:09.133962: \n",
      "2023-08-16 04:48:09.134094: Epoch 97\n",
      "2023-08-16 04:48:09.134220: Current learning rate: 0.0026\n",
      "2023-08-16 04:50:28.390404: train_loss -0.6175\n",
      "2023-08-16 04:50:28.397947: val_loss -0.5279\n",
      "2023-08-16 04:50:28.398058: Pseudo dice [0.5993]\n",
      "2023-08-16 04:50:28.398145: Epoch time: 139.26 s\n",
      "2023-08-16 04:50:30.310208: \n",
      "2023-08-16 04:50:30.310367: Epoch 98\n",
      "2023-08-16 04:50:30.310474: Current learning rate: 0.00252\n",
      "2023-08-16 04:52:59.763847: train_loss -0.606\n",
      "2023-08-16 04:52:59.780040: val_loss -0.5129\n",
      "2023-08-16 04:52:59.780193: Pseudo dice [0.6387]\n",
      "2023-08-16 04:52:59.780268: Epoch time: 149.46 s\n",
      "2023-08-16 04:52:59.780327: Yayy! New best EMA pseudo Dice: 0.5691\n",
      "2023-08-16 04:53:03.685984: \n",
      "2023-08-16 04:53:03.686115: Epoch 99\n",
      "2023-08-16 04:53:03.686235: Current learning rate: 0.00243\n",
      "2023-08-16 04:55:29.278913: train_loss -0.627\n",
      "2023-08-16 04:55:29.283558: val_loss -0.3866\n",
      "2023-08-16 04:55:29.283648: Pseudo dice [0.4073]\n",
      "2023-08-16 04:55:29.283729: Epoch time: 145.59 s\n",
      "2023-08-16 04:55:32.552523: \n",
      "2023-08-16 04:55:32.552663: Epoch 100\n",
      "2023-08-16 04:55:32.552770: Current learning rate: 0.00235\n",
      "2023-08-16 04:57:51.505565: train_loss -0.6064\n",
      "2023-08-16 04:57:51.509488: val_loss -0.4572\n",
      "2023-08-16 04:57:51.509587: Pseudo dice [0.4727]\n",
      "2023-08-16 04:57:51.509672: Epoch time: 138.95 s\n",
      "2023-08-16 04:57:53.632838: \n",
      "2023-08-16 04:57:53.632980: Epoch 101\n",
      "2023-08-16 04:57:53.633092: Current learning rate: 0.00226\n",
      "2023-08-16 05:00:18.682477: train_loss -0.6026\n",
      "2023-08-16 05:00:18.685443: val_loss -0.494\n",
      "2023-08-16 05:00:18.687024: Pseudo dice [0.5631]\n",
      "2023-08-16 05:00:18.687177: Epoch time: 145.05 s\n",
      "2023-08-16 05:00:20.901523: \n",
      "2023-08-16 05:00:20.901648: Epoch 102\n",
      "2023-08-16 05:00:20.901761: Current learning rate: 0.00218\n",
      "2023-08-16 05:02:46.170163: train_loss -0.5959\n",
      "2023-08-16 05:02:46.172512: val_loss -0.4032\n",
      "2023-08-16 05:02:46.172603: Pseudo dice [0.4463]\n",
      "2023-08-16 05:02:46.172687: Epoch time: 145.27 s\n",
      "2023-08-16 05:02:48.506016: \n",
      "2023-08-16 05:02:48.506310: Epoch 103\n",
      "2023-08-16 05:02:48.506488: Current learning rate: 0.00209\n",
      "2023-08-16 05:05:19.568093: train_loss -0.6093\n",
      "2023-08-16 05:05:19.568778: val_loss -0.5348\n",
      "2023-08-16 05:05:19.568864: Pseudo dice [0.6111]\n",
      "2023-08-16 05:05:19.568945: Epoch time: 151.06 s\n",
      "2023-08-16 05:05:21.509577: \n",
      "2023-08-16 05:05:21.509707: Epoch 104\n",
      "2023-08-16 05:05:21.509808: Current learning rate: 0.00201\n",
      "2023-08-16 05:07:43.684178: train_loss -0.5714\n",
      "2023-08-16 05:07:43.684926: val_loss -0.4885\n",
      "2023-08-16 05:07:43.685017: Pseudo dice [0.5055]\n",
      "2023-08-16 05:07:43.685104: Epoch time: 142.18 s\n",
      "2023-08-16 05:07:45.622317: \n",
      "2023-08-16 05:07:45.622441: Epoch 105\n",
      "2023-08-16 05:07:45.622555: Current learning rate: 0.00192\n",
      "2023-08-16 05:10:17.537193: train_loss -0.559\n",
      "2023-08-16 05:10:17.540358: val_loss -0.4637\n",
      "2023-08-16 05:10:17.540459: Pseudo dice [0.5158]\n",
      "2023-08-16 05:10:17.540533: Epoch time: 151.92 s\n",
      "2023-08-16 05:10:19.792830: \n",
      "2023-08-16 05:10:19.792986: Epoch 106\n",
      "2023-08-16 05:10:19.793116: Current learning rate: 0.00184\n",
      "2023-08-16 05:12:45.400772: train_loss -0.5901\n",
      "2023-08-16 05:12:45.402615: val_loss -0.4355\n",
      "2023-08-16 05:12:45.402731: Pseudo dice [0.3116]\n",
      "2023-08-16 05:12:45.402819: Epoch time: 145.61 s\n",
      "2023-08-16 05:12:47.414383: \n",
      "2023-08-16 05:12:47.414521: Epoch 107\n",
      "2023-08-16 05:12:47.414633: Current learning rate: 0.00175\n",
      "2023-08-16 05:15:12.086916: train_loss -0.6078\n",
      "2023-08-16 05:15:12.088790: val_loss -0.4243\n",
      "2023-08-16 05:15:12.088877: Pseudo dice [0.5434]\n",
      "2023-08-16 05:15:12.088959: Epoch time: 144.67 s\n",
      "2023-08-16 05:15:14.057165: \n",
      "2023-08-16 05:15:14.057629: Epoch 108\n",
      "2023-08-16 05:15:14.057980: Current learning rate: 0.00166\n",
      "2023-08-16 05:17:35.643909: train_loss -0.5931\n",
      "2023-08-16 05:17:35.647176: val_loss -0.3907\n",
      "2023-08-16 05:17:35.647297: Pseudo dice [0.4043]\n",
      "2023-08-16 05:17:35.647380: Epoch time: 141.59 s\n",
      "2023-08-16 05:17:37.743790: \n",
      "2023-08-16 05:17:37.743955: Epoch 109\n",
      "2023-08-16 05:17:37.744062: Current learning rate: 0.00157\n",
      "2023-08-16 05:19:56.437015: train_loss -0.6157\n",
      "2023-08-16 05:19:56.439052: val_loss -0.4435\n",
      "2023-08-16 05:19:56.439132: Pseudo dice [0.5145]\n",
      "2023-08-16 05:19:56.439209: Epoch time: 138.69 s\n",
      "2023-08-16 05:19:58.445191: \n",
      "2023-08-16 05:19:58.445326: Epoch 110\n",
      "2023-08-16 05:19:58.445427: Current learning rate: 0.00148\n",
      "2023-08-16 05:22:20.349161: train_loss -0.5597\n",
      "2023-08-16 05:22:20.351526: val_loss -0.4895\n",
      "2023-08-16 05:22:20.351610: Pseudo dice [0.5377]\n",
      "2023-08-16 05:22:20.351693: Epoch time: 141.91 s\n",
      "2023-08-16 05:22:22.247738: \n",
      "2023-08-16 05:22:22.247924: Epoch 111\n",
      "2023-08-16 05:22:22.248029: Current learning rate: 0.00139\n",
      "2023-08-16 05:24:38.294756: train_loss -0.6236\n",
      "2023-08-16 05:24:38.297832: val_loss -0.4255\n",
      "2023-08-16 05:24:38.297932: Pseudo dice [0.4803]\n",
      "2023-08-16 05:24:38.298009: Epoch time: 136.05 s\n",
      "2023-08-16 05:24:40.188108: \n",
      "2023-08-16 05:24:40.188258: Epoch 112\n",
      "2023-08-16 05:24:40.188367: Current learning rate: 0.0013\n",
      "2023-08-16 05:26:57.049751: train_loss -0.5856\n",
      "2023-08-16 05:26:57.052335: val_loss -0.4735\n",
      "2023-08-16 05:26:57.052449: Pseudo dice [0.6343]\n",
      "2023-08-16 05:26:57.052538: Epoch time: 136.86 s\n",
      "2023-08-16 05:26:59.241652: \n",
      "2023-08-16 05:26:59.241796: Epoch 113\n",
      "2023-08-16 05:26:59.241923: Current learning rate: 0.00121\n",
      "2023-08-16 05:29:25.980617: train_loss -0.5743\n",
      "2023-08-16 05:29:25.982229: val_loss -0.5582\n",
      "2023-08-16 05:29:25.982315: Pseudo dice [0.6348]\n",
      "2023-08-16 05:29:25.982395: Epoch time: 146.74 s\n",
      "2023-08-16 05:29:27.928940: \n",
      "2023-08-16 05:29:27.929636: Epoch 114\n",
      "2023-08-16 05:29:27.929951: Current learning rate: 0.00112\n",
      "2023-08-16 05:31:44.774595: train_loss -0.5828\n",
      "2023-08-16 05:31:44.775206: val_loss -0.419\n",
      "2023-08-16 05:31:44.775439: Pseudo dice [0.3955]\n",
      "2023-08-16 05:31:44.775529: Epoch time: 136.85 s\n",
      "2023-08-16 05:31:46.755514: \n",
      "2023-08-16 05:31:46.755773: Epoch 115\n",
      "2023-08-16 05:31:46.756264: Current learning rate: 0.00103\n",
      "2023-08-16 05:34:14.651793: train_loss -0.6243\n",
      "2023-08-16 05:34:14.653143: val_loss -0.4596\n",
      "2023-08-16 05:34:14.653234: Pseudo dice [0.4811]\n",
      "2023-08-16 05:34:14.653311: Epoch time: 147.9 s\n",
      "2023-08-16 05:34:16.791675: \n",
      "2023-08-16 05:34:16.791830: Epoch 116\n",
      "2023-08-16 05:34:16.791969: Current learning rate: 0.00094\n",
      "2023-08-16 05:36:36.351339: train_loss -0.61\n",
      "2023-08-16 05:36:36.358009: val_loss -0.4935\n",
      "2023-08-16 05:36:36.358441: Pseudo dice [0.5549]\n",
      "2023-08-16 05:36:36.358814: Epoch time: 139.56 s\n",
      "2023-08-16 05:36:38.640722: \n",
      "2023-08-16 05:36:38.640879: Epoch 117\n",
      "2023-08-16 05:36:38.640986: Current learning rate: 0.00084\n",
      "2023-08-16 05:39:05.752101: train_loss -0.6236\n",
      "2023-08-16 05:39:05.753721: val_loss -0.4864\n",
      "2023-08-16 05:39:05.753842: Pseudo dice [0.5639]\n",
      "2023-08-16 05:39:05.753927: Epoch time: 147.11 s\n",
      "2023-08-16 05:39:08.208748: \n",
      "2023-08-16 05:39:08.208902: Epoch 118\n",
      "2023-08-16 05:39:08.209023: Current learning rate: 0.00075\n",
      "2023-08-16 05:41:26.839866: train_loss -0.6468\n",
      "2023-08-16 05:41:26.840648: val_loss -0.4187\n",
      "2023-08-16 05:41:26.840760: Pseudo dice [0.4201]\n",
      "2023-08-16 05:41:26.840988: Epoch time: 138.63 s\n",
      "2023-08-16 05:41:29.838074: \n",
      "2023-08-16 05:41:29.838198: Epoch 119\n",
      "2023-08-16 05:41:29.838309: Current learning rate: 0.00065\n",
      "2023-08-16 05:43:56.135114: train_loss -0.6014\n",
      "2023-08-16 05:43:56.136833: val_loss -0.4624\n",
      "2023-08-16 05:43:56.136940: Pseudo dice [0.502]\n",
      "2023-08-16 05:43:56.137032: Epoch time: 146.3 s\n",
      "2023-08-16 05:43:58.352272: \n",
      "2023-08-16 05:43:58.352422: Epoch 120\n",
      "2023-08-16 05:43:58.352537: Current learning rate: 0.00055\n",
      "2023-08-16 05:46:15.401506: train_loss -0.6193\n",
      "2023-08-16 05:46:15.402922: val_loss -0.4937\n",
      "2023-08-16 05:46:15.403095: Pseudo dice [0.4739]\n",
      "2023-08-16 05:46:15.403293: Epoch time: 137.05 s\n",
      "2023-08-16 05:46:17.420308: \n",
      "2023-08-16 05:46:17.420453: Epoch 121\n",
      "2023-08-16 05:46:17.420554: Current learning rate: 0.00045\n",
      "2023-08-16 05:49:00.683929: train_loss -0.6236\n",
      "2023-08-16 05:49:00.685322: val_loss -0.5027\n",
      "2023-08-16 05:49:00.685643: Pseudo dice [0.539]\n",
      "2023-08-16 05:49:00.685732: Epoch time: 163.26 s\n",
      "2023-08-16 05:49:03.036353: \n",
      "2023-08-16 05:49:03.036525: Epoch 122\n",
      "2023-08-16 05:49:03.036640: Current learning rate: 0.00035\n",
      "2023-08-16 05:51:53.460733: train_loss -0.617\n",
      "2023-08-16 05:51:53.471617: val_loss -0.4981\n",
      "2023-08-16 05:51:53.472017: Pseudo dice [0.5545]\n",
      "2023-08-16 05:51:53.472246: Epoch time: 170.43 s\n",
      "2023-08-16 05:51:55.554771: \n",
      "2023-08-16 05:51:55.554924: Epoch 123\n",
      "2023-08-16 05:51:55.555040: Current learning rate: 0.00024\n",
      "2023-08-16 05:54:54.859707: train_loss -0.6329\n",
      "2023-08-16 05:54:54.861413: val_loss -0.508\n",
      "2023-08-16 05:54:54.861546: Pseudo dice [0.462]\n",
      "2023-08-16 05:54:54.861654: Epoch time: 179.31 s\n",
      "2023-08-16 05:54:56.792328: \n",
      "2023-08-16 05:54:56.792485: Epoch 124\n",
      "2023-08-16 05:54:56.792583: Current learning rate: 0.00013\n",
      "2023-08-16 05:57:55.788729: train_loss -0.6315\n",
      "2023-08-16 05:57:55.794240: val_loss -0.529\n",
      "2023-08-16 05:57:55.794610: Pseudo dice [0.694]\n",
      "2023-08-16 05:57:55.794866: Epoch time: 179.0 s\n",
      "2023-08-16 05:57:58.179620: Training done.\n",
      "2023-08-16 05:57:58.293065: Using splits from existing split file: nnUNet_preprocessed/Dataset013_PETCTDB/splits_final.json\n",
      "2023-08-16 05:57:58.293734: The split file contains 5 splits.\n",
      "2023-08-16 05:57:58.293823: Desired fold for training: 1\n",
      "2023-08-16 05:57:58.293876: This split has 87 training and 22 validation cases.\n",
      "2023-08-16 05:57:58.294242: predicting patient02\n",
      "2023-08-16 05:58:34.516320: predicting patient06\n",
      "2023-08-16 05:59:53.992570: predicting patient08\n",
      "2023-08-16 06:00:37.876940: predicting patient11\n",
      "2023-08-16 06:01:13.265061: predicting patient16\n",
      "2023-08-16 06:02:06.223337: predicting patient21\n",
      "2023-08-16 06:02:32.729416: predicting patient26\n",
      "2023-08-16 06:03:17.153223: predicting patient28\n",
      "2023-08-16 06:04:36.907636: predicting patient36\n",
      "2023-08-16 06:05:12.424251: predicting patient39\n",
      "2023-08-16 06:05:57.152568: predicting patient40\n",
      "2023-08-16 06:06:33.008110: predicting patient42\n",
      "2023-08-16 06:07:08.745967: predicting patient43\n",
      "2023-08-16 06:07:44.383747: predicting patient48\n",
      "2023-08-16 06:08:28.802254: predicting patient51\n",
      "2023-08-16 06:09:13.473013: predicting patient53\n",
      "2023-08-16 06:09:58.008208: predicting patient56\n",
      "2023-08-16 06:10:42.329231: predicting patient57\n",
      "2023-08-16 06:11:18.036425: predicting patient63\n",
      "2023-08-16 06:12:02.662246: predicting patient75\n",
      "2023-08-16 06:12:47.024939: predicting patient83\n",
      "2023-08-16 06:13:22.871929: predicting patient90\n",
      "2023-08-16 06:14:51.046011: Validation complete\n",
      "2023-08-16 06:14:51.046526: Mean Validation Dice:  0.35883652632691204\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_train 013 3d_fullres 1 --npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85f13d74-e797-4871-ac1b-2ab1fc37cab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/nnUNetv2_find_best_configuration\", line 8, in <module>\n",
      "    sys.exit(find_best_configuration_entry_point())\n",
      "  File \"/home/nnUNet/nnunetv2/evaluation/find_best_configuration.py\", line 295, in find_best_configuration_entry_point\n",
      "    find_best_configuration(dataset_name, model_dict, allow_ensembling=not args.disable_ensembling,\n",
      "  File \"/home/nnUNet/nnunetv2/evaluation/find_best_configuration.py\", line 100, in find_best_configuration\n",
      "    accumulate_cv_results(output_folder, merged_output_folder, folds, num_processes, overwrite)\n",
      "  File \"/home/nnUNet/nnunetv2/evaluation/accumulate_cv_results.py\", line 36, in accumulate_cv_results\n",
      "    raise RuntimeError(f\"fold {f} of model {trained_model_folder} is missing. Please train it!\")\n",
      "RuntimeError: fold 0 of model result_folder/Dataset013_PETCTDB/nnUNetTrainer__nnUNetPlans__3d_fullres is missing. Please train it!\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_find_best_configuration 013 -c 3d_fullres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b3534d-b53c-45dc-b9af-884539df9649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4cb40b-7d39-42af-a80f-74cc6942357d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2965fc9b-3845-43fc-a630-5eea0f10716a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m test_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/Dataset013_PETCTDB/imagesTs\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m test_img_name \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m test_img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(nib\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(test_dir,test_img_name))\u001b[38;5;241m.\u001b[39mdataobj)[:,:,:\u001b[38;5;241m5\u001b[39m]\n\u001b[1;32m      6\u001b[0m predicted_img_name \u001b[38;5;241m=\u001b[39m test_img_name[:test_img_name\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_0000.nii.gz\u001b[39m\u001b[38;5;124m'\u001b[39m)]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.nii.gz\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "test_dir = 'data/Dataset013_PETCTDB/imagesTs'\n",
    "import numpy as np\n",
    "\n",
    "test_img_name = os.listdir(test_dir)[np.random.randint(0,40)]\n",
    "test_img = np.array(nib.load(os.path.join(test_dir,test_img_name)).dataobj)[:,:,:5]\n",
    "predicted_img_name = test_img_name[:test_img_name.find('_0000.nii.gz')]+'.nii.gz'\n",
    "predicted_label = np.array(nib.load(os.path.join(result_dir,predicted_img_name)).dataobj)[:,:,:5]\n",
    "print('Test Image Shape: ',test_img.shape)\n",
    "print(\"Predicted Image Shape:\",predicted_label.shape)\n",
    "\n",
    "max_rows = 2\n",
    "max_cols = test_img.shape[2]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=max_rows, ncols=max_cols, figsize=(20,8))\n",
    "for idx in range(max_cols):\n",
    "    axes[0, idx].axis(\"off\") \n",
    "    axes[0, idx].set_title('Train Image'+str(idx+1))\n",
    "    axes[0 ,idx].imshow(test_img[:,:,idx], cmap=\"gray\")\n",
    "for idx in range(max_cols):    \n",
    "    axes[1, idx].axis(\"off\")\n",
    "    axes[1, idx].set_title('Train Label'+str(idx+1))\n",
    "    axes[1, idx].imshow(predicted_label[:,:,idx])\n",
    "    \n",
    "plt.subplots_adjust(wspace=.1, hspace=.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdebc08-1027-4288-b988-a2b2d61a7327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
